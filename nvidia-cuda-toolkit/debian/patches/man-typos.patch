Description: fix spelling-error-in-manpage and other typos
Author: Andreas Beckmann <anbe@debian.org>
Author: Graham Inggs <graham@nerve.org.za>
Last-Update: 2017-11-06

--- a/nvidia-cuda/doc/man/man3/CUDART_EXECUTION.3
+++ b/nvidia-cuda/doc/man/man3/CUDART_EXECUTION.3
@@ -82,7 +82,7 @@ Note that some function attributes such
 .RS 4
 Note that this function may also return error codes from previous, asynchronous launches. 
 .PP
-Use of a string naming a function as the \fCfunc\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+Use of a string naming a function as the \fCfunc\fP parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
@@ -159,7 +159,7 @@ The supported cache configurations are:
 .RS 4
 Note that this function may also return error codes from previous, asynchronous launches. 
 .PP
-Use of a string naming a function as the \fCfunc\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+Use of a string naming a function as the \fCfunc\fP parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
@@ -205,7 +205,7 @@ cudaSharedMemBankSizeEightByte: set shar
 .RS 4
 Note that this function may also return error codes from previous, asynchronous launches. 
 .PP
-Use of a string naming a function as the \fCfunc\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+Use of a string naming a function as the \fCfunc\fP parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
@@ -304,9 +304,9 @@ For templated functions, pass the functi
 .RS 4
 \fIfunc\fP - Device function symbol 
 .br
-\fIgridDim\fP - Grid dimentions 
+\fIgridDim\fP - Grid dimensions 
 .br
-\fIblockDim\fP - Block dimentions 
+\fIblockDim\fP - Block dimensions 
 .br
 \fIargs\fP - Arguments 
 .br
@@ -339,7 +339,7 @@ Invokes kernels as specified in the \fCl
 .PP
 No two kernels can be launched on the same device. All the devices targeted by this multi-device launch must be identical. All devices must have a non-zero value for the device attribute \fBcudaDevAttrCooperativeMultiDeviceLaunch\fP.
 .PP
-The same kernel must be launched on all devices. Note that any __device__ or __constant__ variables are independently instantiated on every device. It is the application's responsiblity to ensure these variables are initialized and used appropriately.
+The same kernel must be launched on all devices. Note that any __device__ or __constant__ variables are independently instantiated on every device. It is the application's responsibility to ensure these variables are initialized and used appropriately.
 .PP
 The size of the grids as specified in blocks, the size of the blocks themselves and the amount of shared memory used by each thread block must also match across all launched kernels.
 .PP
@@ -426,9 +426,9 @@ For templated functions, pass the functi
 .RS 4
 \fIfunc\fP - Device function symbol 
 .br
-\fIgridDim\fP - Grid dimentions 
+\fIgridDim\fP - Grid dimensions 
 .br
-\fIblockDim\fP - Block dimentions 
+\fIblockDim\fP - Block dimensions 
 .br
 \fIargs\fP - Arguments 
 .br
--- a/nvidia-cuda/doc/man/man3/CUDART_MEMORY.3
+++ b/nvidia-cuda/doc/man/man3/CUDART_MEMORY.3
@@ -438,7 +438,7 @@ Returns in \fC*devPtr\fP the address of
 .RS 4
 Note that this function may also return error codes from previous, asynchronous launches. 
 .PP
-Use of a string naming a variable as the \fCsymbol\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+Use of a string naming a variable as the \fCsymbol\fP parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
@@ -467,7 +467,7 @@ Returns in \fC*size\fP the size of symbo
 .RS 4
 Note that this function may also return error codes from previous, asynchronous launches. 
 .PP
-Use of a string naming a variable as the \fCsymbol\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+Use of a string naming a variable as the \fCsymbol\fP parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
@@ -895,7 +895,7 @@ Allocates \fCsize\fP bytes of managed me
 .PP
 \fCflags\fP specifies the default stream association for this allocation. \fCflags\fP must be one of \fBcudaMemAttachGlobal\fP or \fBcudaMemAttachHost\fP. The default value for \fCflags\fP is \fBcudaMemAttachGlobal\fP. If \fBcudaMemAttachGlobal\fP is specified, then this memory is accessible from any stream on any device. If \fBcudaMemAttachHost\fP is specified, then the allocation should not be accessed from devices that have a zero value for the device attribute \fBcudaDevAttrConcurrentManagedAccess\fP; an explicit call to \fBcudaStreamAttachMemAsync\fP will be required to enable access on such devices.
 .PP
-If the association is later changed via \fBcudaStreamAttachMemAsync\fP to a single stream, the default association, as specifed during \fBcudaMallocManaged\fP, is restored when that stream is destroyed. For __managed__ variables, the default association is always \fBcudaMemAttachGlobal\fP. Note that destroying a stream is an asynchronous operation, and as a result, the change to default association won't happen until all work in the stream has completed.
+If the association is later changed via \fBcudaStreamAttachMemAsync\fP to a single stream, the default association, as specified during \fBcudaMallocManaged\fP, is restored when that stream is destroyed. For __managed__ variables, the default association is always \fBcudaMemAttachGlobal\fP. Note that destroying a stream is an asynchronous operation, and as a result, the change to default association won't happen until all work in the stream has completed.
 .PP
 Memory allocated with \fBcudaMallocManaged\fP should be released with \fBcudaFree\fP.
 .PP
@@ -1484,7 +1484,7 @@ struct cudaMemcpy3DParms {
 .fi
 .PP
 .PP
-\fBcudaMemcpy3D()\fP copies data betwen two 3D objects. The source and destination objects may be in either host memory, device memory, or a CUDA array. The source, destination, extent, and kind of copy performed is specified by the \fBcudaMemcpy3DParms\fP struct which should be initialized to zero before use: 
+\fBcudaMemcpy3D()\fP copies data between two 3D objects. The source and destination objects may be in either host memory, device memory, or a CUDA array. The source, destination, extent, and kind of copy performed is specified by the \fBcudaMemcpy3DParms\fP struct which should be initialized to zero before use: 
 .PP
 .nf
 cudaMemcpy3DParms myParms = {0};
@@ -1562,7 +1562,7 @@ struct cudaMemcpy3DParms {
 .fi
 .PP
 .PP
-\fBcudaMemcpy3DAsync()\fP copies data betwen two 3D objects. The source and destination objects may be in either host memory, device memory, or a CUDA array. The source, destination, extent, and kind of copy performed is specified by the \fBcudaMemcpy3DParms\fP struct which should be initialized to zero before use: 
+\fBcudaMemcpy3DAsync()\fP copies data between two 3D objects. The source and destination objects may be in either host memory, device memory, or a CUDA array. The source, destination, extent, and kind of copy performed is specified by the \fBcudaMemcpy3DParms\fP struct which should be initialized to zero before use: 
 .PP
 .nf
 cudaMemcpy3DParms myParms = {0};
@@ -1867,7 +1867,7 @@ Note that this function may also return
 .PP
 This function exhibits  behavior for most use cases. 
 .PP
-Use of a string naming a variable as the \fCsymbol\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+Use of a string naming a variable as the \fCsymbol\fP parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
@@ -1910,7 +1910,7 @@ This function exhibits  behavior for mos
 .PP
 This function uses standard  semantics. 
 .PP
-Use of a string naming a variable as the \fCsymbol\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+Use of a string naming a variable as the \fCsymbol\fP parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
@@ -2105,7 +2105,7 @@ Note that this function may also return
 .PP
 This function exhibits  behavior for most use cases. 
 .PP
-Use of a string naming a variable as the \fCsymbol\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+Use of a string naming a variable as the \fCsymbol\fP parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
@@ -2148,7 +2148,7 @@ This function exhibits  behavior for mos
 .PP
 This function uses standard  semantics. 
 .PP
-Use of a string naming a variable as the \fCsymbol\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+Use of a string naming a variable as the \fCsymbol\fP parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
--- a/nvidia-cuda/doc/man/man3/CUDART_SURFACE.3
+++ b/nvidia-cuda/doc/man/man3/CUDART_SURFACE.3
@@ -73,7 +73,7 @@ Returns in \fC*surfref\fP the structure
 .RS 4
 Note that this function may also return error codes from previous, asynchronous launches. 
 .PP
-Use of a string naming a variable as the \fCsymbol\fP paramater was removed in CUDA 5.0.
+Use of a string naming a variable as the \fCsymbol\fP parameter was removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
--- a/nvidia-cuda/doc/man/man3/CUDART_TEXTURE.3
+++ b/nvidia-cuda/doc/man/man3/CUDART_TEXTURE.3
@@ -303,7 +303,7 @@ Returns in \fC*texref\fP the structure a
 .RS 4
 Note that this function may also return error codes from previous, asynchronous launches. 
 .PP
-Use of a string naming a variable as the \fCsymbol\fP paramater was removed in CUDA 5.0.
+Use of a string naming a variable as the \fCsymbol\fP parameter was removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
--- a/nvidia-cuda/doc/man/man3/CUDA_EXEC.3
+++ b/nvidia-cuda/doc/man/man3/CUDA_EXEC.3
@@ -279,7 +279,7 @@ Invokes kernels as specified in the \fCl
 .PP
 No two kernels can be launched on the same device. All the devices targeted by this multi-device launch must be identical. All devices must have a non-zero value for the device attribute \fBCU_DEVICE_ATTRIBUTE_COOPERATIVE_MULTI_DEVICE_LAUNCH\fP.
 .PP
-All kernels launched must be identical with respect to the compiled code. Note that any __device__, __constant__ or __managed__ variables present in the module that owns the kernel launched on each device, are independently instantiated on every device. It is the application's responsiblity to ensure these variables are initialized and used appropriately.
+All kernels launched must be identical with respect to the compiled code. Note that any __device__, __constant__ or __managed__ variables present in the module that owns the kernel launched on each device, are independently instantiated on every device. It is the application's responsibility to ensure these variables are initialized and used appropriately.
 .PP
 The size of the grids as specified in blocks, the size of the blocks themselves and the amount of shared memory used by each thread block must also match across all launched kernels.
 .PP
--- a/nvidia-cuda/doc/man/man3/CUDA_MEM.3
+++ b/nvidia-cuda/doc/man/man3/CUDA_MEM.3
@@ -676,7 +676,7 @@ Note that this function may also return
 
 .SS "\fBCUresult\fP cuIpcCloseMemHandle (\fBCUdeviceptr\fP dptr)"
 .PP
-Unmaps memory returnd by \fBcuIpcOpenMemHandle\fP. The original allocation in the exporting process as well as imported mappings in other processes will be unaffected.
+Unmaps memory returned by \fBcuIpcOpenMemHandle\fP. The original allocation in the exporting process as well as imported mappings in other processes will be unaffected.
 .PP
 Any resources used to enable peer access will be freed if this is the last mapping using them.
 .PP
@@ -875,7 +875,7 @@ Allocates \fCbytesize\fP bytes of manage
 .PP
 \fCflags\fP specifies the default stream association for this allocation. \fCflags\fP must be one of \fBCU_MEM_ATTACH_GLOBAL\fP or \fBCU_MEM_ATTACH_HOST\fP. If \fBCU_MEM_ATTACH_GLOBAL\fP is specified, then this memory is accessible from any stream on any device. If \fBCU_MEM_ATTACH_HOST\fP is specified, then the allocation should not be accessed from devices that have a zero value for the device attribute \fBCU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS\fP; an explicit call to \fBcuStreamAttachMemAsync\fP will be required to enable access on such devices.
 .PP
-If the association is later changed via \fBcuStreamAttachMemAsync\fP to a single stream, the default association as specifed during \fBcuMemAllocManaged\fP is restored when that stream is destroyed. For __managed__ variables, the default association is always \fBCU_MEM_ATTACH_GLOBAL\fP. Note that destroying a stream is an asynchronous operation, and as a result, the change to default association won't happen until all work in the stream has completed.
+If the association is later changed via \fBcuStreamAttachMemAsync\fP to a single stream, the default association as specified during \fBcuMemAllocManaged\fP is restored when that stream is destroyed. For __managed__ variables, the default association is always \fBCU_MEM_ATTACH_GLOBAL\fP. Note that destroying a stream is an asynchronous operation, and as a result, the change to default association won't happen until all work in the stream has completed.
 .PP
 Memory allocated with \fBcuMemAllocManaged\fP should be released with \fBcuMemFree\fP.
 .PP
--- a/nvidia-cuda/doc/man/man3/CUDART_EXECUTION_DEPRECATED.3
+++ b/nvidia-cuda/doc/man/man3/CUDART_EXECUTION_DEPRECATED.3
@@ -89,7 +89,7 @@ Launches the function \fCfunc\fP on the
 .RS 4
 Note that this function may also return error codes from previous, asynchronous launches. 
 .PP
-Use of a string naming a variable as the \fCsymbol\fP paramater was removed in CUDA 5.0.
+Use of a string naming a variable as the \fCsymbol\fP parameter was removed in CUDA 5.0.
 .RE
 .PP
 \fBcudaLaunchKernel (C API)\fP, \fBcudaFuncSetCacheConfig (C API)\fP, \fBcudaFuncGetAttributes (C API)\fP, \fBcudaLaunch (C++ API)\fP, \fBcudaSetDoubleForDevice\fP, \fBcudaSetDoubleForHost\fP, \fBcudaSetupArgument (C API)\fP, \fBcudaThreadGetCacheConfig\fP, \fBcudaThreadSetCacheConfig\fP 
--- a/nvidia-cuda/doc/man/man3/CUDART_HIGHLEVEL.3
+++ b/nvidia-cuda/doc/man/man3/CUDART_HIGHLEVEL.3
@@ -146,7 +146,7 @@ C++ API Routines \- C++-style interface
 .ti -1c
 .RI "template<class T > CUDART_DEVICE \fBcudaError_t\fP \fBcudaOccupancyMaxPotentialBlockSizeWithFlags\fP (int *minGridSize, int *blockSize, T func, size_t dynamicSMemSize=0, int blockSizeLimit=0, unsigned int flags=0)"
 .br
-.RI "\fIReturns grid and block size that achived maximum potential occupancy for a device function with the specified flags. \fP"
+.RI "\fIReturns grid and block size that achieved maximum potential occupancy for a device function with the specified flags. \fP"
 .ti -1c
 .RI "template<class T > \fBcudaError_t\fP \fBcudaSetupArgument\fP (T arg, size_t offset)"
 .br
@@ -753,9 +753,9 @@ If the kernel has N parameters the \fCar
 .RS 4
 \fIfunc\fP - Device function symbol 
 .br
-\fIgridDim\fP - Grid dimentions 
+\fIgridDim\fP - Grid dimensions 
 .br
-\fIblockDim\fP - Block dimentions 
+\fIblockDim\fP - Block dimensions 
 .br
 \fIargs\fP - Arguments 
 .br
@@ -793,9 +793,9 @@ If the kernel has N parameters the \fCar
 .RS 4
 \fIfunc\fP - Device function symbol 
 .br
-\fIgridDim\fP - Grid dimentions 
+\fIgridDim\fP - Grid dimensions 
 .br
-\fIblockDim\fP - Block dimentions 
+\fIblockDim\fP - Block dimensions 
 .br
 \fIargs\fP - Arguments 
 .br
@@ -873,7 +873,7 @@ Allocates \fCsize\fP bytes of managed me
 .PP
 \fCflags\fP specifies the default stream association for this allocation. \fCflags\fP must be one of \fBcudaMemAttachGlobal\fP or \fBcudaMemAttachHost\fP. The default value for \fCflags\fP is \fBcudaMemAttachGlobal\fP. If \fBcudaMemAttachGlobal\fP is specified, then this memory is accessible from any stream on any device. If \fBcudaMemAttachHost\fP is specified, then the allocation should not be accessed from devices that have a zero value for the device attribute \fBcudaDevAttrConcurrentManagedAccess\fP; an explicit call to \fBcudaStreamAttachMemAsync\fP will be required to enable access on such devices.
 .PP
-If the association is later changed via \fBcudaStreamAttachMemAsync\fP to a single stream, the default association, as specifed during \fBcudaMallocManaged\fP, is restored when that stream is destroyed. For __managed__ variables, the default association is always \fBcudaMemAttachGlobal\fP. Note that destroying a stream is an asynchronous operation, and as a result, the change to default association won't happen until all work in the stream has completed.
+If the association is later changed via \fBcudaStreamAttachMemAsync\fP to a single stream, the default association, as specified during \fBcudaMallocManaged\fP, is restored when that stream is destroyed. For __managed__ variables, the default association is always \fBcudaMemAttachGlobal\fP. Note that destroying a stream is an asynchronous operation, and as a result, the change to default association won't happen until all work in the stream has completed.
 .PP
 Memory allocated with \fBcudaMallocManaged\fP should be released with \fBcudaFree\fP.
 .PP
@@ -940,7 +940,7 @@ Note that this function may also return
 .PP
 This function exhibits  behavior for most use cases. 
 .PP
-Use of a string naming a variable as the \fCsymbol\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+Use of a string naming a variable as the \fCsymbol\fP parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
@@ -981,7 +981,7 @@ Note that this function may also return
 .PP
 This function exhibits  behavior for most use cases. 
 .PP
-Use of a string naming a variable as the \fCsymbol\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+Use of a string naming a variable as the \fCsymbol\fP parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
@@ -1018,7 +1018,7 @@ Note that this function may also return
 .PP
 This function exhibits  behavior for most use cases. 
 .PP
-Use of a string naming a variable as the \fCsymbol\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+Use of a string naming a variable as the \fCsymbol\fP parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
@@ -1059,7 +1059,7 @@ Note that this function may also return
 .PP
 This function exhibits  behavior for most use cases. 
 .PP
-Use of a string naming a variable as the \fCsymbol\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+Use of a string naming a variable as the \fCsymbol\fP parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
 .RE
 .PP
 \fBSee also:\fP
@@ -1076,7 +1076,7 @@ Returns in \fC*numBlocks\fP the maximum
 .RS 4
 \fInumBlocks\fP - Returned occupancy 
 .br
-\fIfunc\fP - Kernel function for which occupancy is calulated 
+\fIfunc\fP - Kernel function for which occupancy is calculated 
 .br
 \fIblockSize\fP - Block size the kernel is intended to be launched with 
 .br
@@ -1125,7 +1125,7 @@ The \fCflags\fP parameter controls how s
 .RS 4
 \fInumBlocks\fP - Returned occupancy 
 .br
-\fIfunc\fP - Kernel function for which occupancy is calulated 
+\fIfunc\fP - Kernel function for which occupancy is calculated 
 .br
 \fIblockSize\fP - Block size the kernel is intended to be launched with 
 .br
--- a/nvidia-cuda/doc/man/man3/CUDA_PRIMARY_CTX.3
+++ b/nvidia-cuda/doc/man/man3/CUDA_PRIMARY_CTX.3
@@ -152,7 +152,7 @@ Note that this function may also return
 
 .SS "\fBCUresult\fP cuDevicePrimaryCtxSetFlags (\fBCUdevice\fP dev, unsigned int flags)"
 .PP
-Sets the flags for the primary context on the device overwriting perviously set ones. If the primary context is already created \fBCUDA_ERROR_PRIMARY_CONTEXT_ACTIVE\fP is returned.
+Sets the flags for the primary context on the device overwriting previously set ones. If the primary context is already created \fBCUDA_ERROR_PRIMARY_CONTEXT_ACTIVE\fP is returned.
 .PP
 The three LSBs of the \fCflags\fP parameter can be used to control how the OS thread, which owns the CUDA context at the time of an API call, interacts with the OS scheduler when waiting for results from the GPU. Only one of the scheduling flags can be set when creating a context.
 .PP
--- a/nvidia-cuda/doc/man/man1/cuda-gdb.1
+++ b/nvidia-cuda/doc/man/man1/cuda-gdb.1
@@ -183,7 +183,7 @@ permission to that directory.
 
 .TP
 \fB~/.cuda-gdbinit\fR
-Per user configuration file. The file format is indentical to
+Per user configuration file. The file format is identical to
 ~/.gdbinit. See \fBgdb\fR(5) for further details.
 .TP
 \fB/tmp/cuda-dbg/\fR
--- a/nvidia-cuda/doc/man/man3/CUDA_DEVICE.3
+++ b/nvidia-cuda/doc/man/man3/CUDA_DEVICE.3
@@ -21,7 +21,7 @@ Device Management \-
 .ti -1c
 .RI "\fBCUresult\fP \fBcuDeviceGetName\fP (char *name, int len, \fBCUdevice\fP dev)"
 .br
-.RI "\fIReturns an identifer string for the device. \fP"
+.RI "\fIReturns an identifier string for the device. \fP"
 .ti -1c
 .RI "\fBCUresult\fP \fBcuDeviceGetUuid\fP (CUuuid *uuid, \fBCUdevice\fP dev)"
 .br
@@ -239,7 +239,7 @@ Returns in \fC*pi\fP the integer value o
 .IP "\(bu" 2
 \fBCU_DEVICE_ATTRIBUTE_SINGLE_TO_DOUBLE_PRECISION_PERF_RATIO\fP: Ratio of single precision performance (in floating-point operations per second) to double precision performance.
 .IP "\(bu" 2
-\fBCU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS\fP: Device suppports coherently accessing pageable memory without calling cudaHostRegister on it.
+\fBCU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS\fP: Device supports coherently accessing pageable memory without calling cudaHostRegister on it.
 .IP "\(bu" 2
 \fBCU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS\fP: Device can coherently access managed memory concurrently with the CPU.
 .IP "\(bu" 2
@@ -247,7 +247,7 @@ Returns in \fC*pi\fP the integer value o
 .IP "\(bu" 2
 \fBCU_DEVICE_ATTRIBUTE_CAN_USE_HOST_POINTER_FOR_REGISTERED_MEM\fP: Device can access host registered memory at the same virtual address as the CPU.
 .IP "\(bu" 2
-\fBCU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK_OPTIN\fP: The maximum per block shared memory size suported on this device. This is the maximum value that can be opted into when using the \fBcuFuncSetAttribute()\fP call. For more details see \fBCU_FUNC_ATTRIBUTE_MAX_DYNAMIC_SHARED_SIZE_BYTES\fP
+\fBCU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK_OPTIN\fP: The maximum per block shared memory size supported on this device. This is the maximum value that can be opted into when using the \fBcuFuncSetAttribute()\fP call. For more details see \fBCU_FUNC_ATTRIBUTE_MAX_DYNAMIC_SHARED_SIZE_BYTES\fP
 .IP "\(bu" 2
 \fBCU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES\fP: Device accesses pageable memory via the host's page tables.
 .IP "\(bu" 2
--- a/nvidia-cuda/doc/man/man3/cuda.h.3
+++ b/nvidia-cuda/doc/man/man3/cuda.h.3
@@ -440,7 +440,7 @@ cuda.h \- Header file for the CUDA Toolk
 .ti -1c
 .RI "\fBCUresult\fP \fBcuDeviceGetName\fP (char *name, int len, \fBCUdevice\fP dev)"
 .br
-.RI "\fIReturns an identifer string for the device. \fP"
+.RI "\fIReturns an identifier string for the device. \fP"
 .ti -1c
 .RI "\fBCUresult\fP \fBcuDeviceGetP2PAttribute\fP (int *value, \fBCUdevice_P2PAttribute\fP attrib, \fBCUdevice\fP srcDevice, \fBCUdevice\fP dstDevice)"
 .br
--- a/nvidia-cuda/doc/html/cuda-driver-api/group__CUDA__TYPES.html
+++ b/nvidia-cuda/doc/html/cuda-driver-api/group__CUDA__TYPES.html
@@ -1993,7 +1993,7 @@
                               </h6>
                               <dl class="enumerator">
                                  <dt><span class="enum-member-name-def">CU_MEM_ADVISE_SET_READ_MOSTLY = <span class="ph ph apiData">1</span></span></dt>
-                                 <dd>Data will mostly be read and only occassionally be written to </dd>
+                                 <dd>Data will mostly be read and only occasionally be written to </dd>
                                  <dt><span class="enum-member-name-def">CU_MEM_ADVISE_UNSET_READ_MOSTLY = <span class="ph ph apiData">2</span></span></dt>
                                  <dd>Undo the effect of <a class="xref" href="group__CUDA__TYPES.html#group__CUDA__TYPES_1ggcfe2ed2d4567745dd4ad41034136fff35a99fb44378c84c56668550b94157fc0" shape="rect">CU_MEM_ADVISE_SET_READ_MOSTLY</a></dd>
                                  <dt><span class="enum-member-name-def">CU_MEM_ADVISE_SET_PREFERRED_LOCATION = <span class="ph ph apiData">3</span></span></dt>
--- a/nvidia-cuda/doc/man/man3/CUDA_TYPES.3
+++ b/nvidia-cuda/doc/man/man3/CUDA_TYPES.3
@@ -1571,7 +1571,7 @@ Memory advise values
 .in +1c
 .TP
 \fB\fICU_MEM_ADVISE_SET_READ_MOSTLY \fP\fP
-Data will mostly be read and only occassionally be written to 
+Data will mostly be read and only occasionally be written to 
 .TP
 \fB\fICU_MEM_ADVISE_UNSET_READ_MOSTLY \fP\fP
 Undo the effect of \fBCU_MEM_ADVISE_SET_READ_MOSTLY\fP 
@@ -1593,7 +1593,7 @@ Let the Unified Memory subsystem decide
 .in +1c
 .TP
 \fB\fICU_MEM_RANGE_ATTRIBUTE_READ_MOSTLY \fP\fP
-Whether the range will mostly be read and only occassionally be written to 
+Whether the range will mostly be read and only occasionally be written to 
 .TP
 \fB\fICU_MEM_RANGE_ATTRIBUTE_PREFERRED_LOCATION \fP\fP
 The preferred location of the range 
@@ -1689,7 +1689,7 @@ Resource types
 .in +1c
 .TP
 \fB\fICU_RESOURCE_TYPE_ARRAY \fP\fP
-Array resoure 
+Array resource 
 .TP
 \fB\fICU_RESOURCE_TYPE_MIPMAPPED_ARRAY \fP\fP
 Mipmapped array resource 
--- a/nvidia-cuda/include/cuda.h
+++ b/nvidia-cuda/include/cuda.h
@@ -751,7 +751,7 @@ typedef enum CUcomputemode_enum {
  * Memory advise values
  */
 typedef enum CUmem_advise_enum {
-    CU_MEM_ADVISE_SET_READ_MOSTLY          = 1, /**< Data will mostly be read and only occassionally be written to */
+    CU_MEM_ADVISE_SET_READ_MOSTLY          = 1, /**< Data will mostly be read and only occasionally be written to */
     CU_MEM_ADVISE_UNSET_READ_MOSTLY        = 2, /**< Undo the effect of ::CU_MEM_ADVISE_SET_READ_MOSTLY */
     CU_MEM_ADVISE_SET_PREFERRED_LOCATION   = 3, /**< Set the preferred location for the data as the specified device */
     CU_MEM_ADVISE_UNSET_PREFERRED_LOCATION = 4, /**< Clear the preferred location for the data */
@@ -760,7 +760,7 @@ typedef enum CUmem_advise_enum {
 } CUmem_advise;
 
 typedef enum CUmem_range_attribute_enum {
-    CU_MEM_RANGE_ATTRIBUTE_READ_MOSTLY            = 1, /**< Whether the range will mostly be read and only occassionally be written to */
+    CU_MEM_RANGE_ATTRIBUTE_READ_MOSTLY            = 1, /**< Whether the range will mostly be read and only occasionally be written to */
     CU_MEM_RANGE_ATTRIBUTE_PREFERRED_LOCATION     = 2, /**< The preferred location of the range */
     CU_MEM_RANGE_ATTRIBUTE_ACCESSED_BY            = 3, /**< Memory range has ::CU_MEM_ADVISE_SET_ACCESSED_BY set for specified device */
     CU_MEM_RANGE_ATTRIBUTE_LAST_PREFETCH_LOCATION = 4  /**< The last location to which the range was prefetched */
@@ -2124,7 +2124,7 @@ CUresult CUDAAPI cuDeviceGet(CUdevice *d
 CUresult CUDAAPI cuDeviceGetCount(int *count);
 
 /**
- * \brief Returns an identifer string for the device
+ * \brief Returns an identifier string for the device
  *
  * Returns an ASCII string identifying the device \p dev in the NULL-terminated
  * string pointed to by \p name. \p len specifies the maximum length of the
@@ -2377,7 +2377,7 @@ CUresult CUDAAPI cuDeviceTotalMem(size_t
  *   supports native atomic operations.
  * - ::CU_DEVICE_ATTRIBUTE_SINGLE_TO_DOUBLE_PRECISION_PERF_RATIO: Ratio of single precision performance
  *   (in floating-point operations per second) to double precision performance.
- * - ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS: Device suppports coherently accessing
+ * - ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS: Device supports coherently accessing
  *   pageable memory without calling cudaHostRegister on it.
  * - ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS: Device can coherently access managed memory
  *   concurrently with the CPU.
@@ -2385,7 +2385,7 @@ CUresult CUDAAPI cuDeviceTotalMem(size_t
  * - ::CU_DEVICE_ATTRIBUTE_CAN_USE_HOST_POINTER_FOR_REGISTERED_MEM: Device can access host registered
  *   memory at the same virtual address as the CPU.
  * -  ::CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK_OPTIN: The maximum per block shared memory size
- *    suported on this device. This is the maximum value that can be opted into when using the cuFuncSetAttribute() call.
+ *    supported on this device. This is the maximum value that can be opted into when using the cuFuncSetAttribute() call.
  *    For more details see ::CU_FUNC_ATTRIBUTE_MAX_DYNAMIC_SHARED_SIZE_BYTES
  * - ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES: Device accesses pageable memory via the host's
  *   page tables.
@@ -2498,7 +2498,7 @@ __CUDA_DEPRECATED CUresult CUDAAPI cuDev
  *
  * \deprecated
  *
- * This function was deprecated as of CUDA 5.0 and its functionality superceded
+ * This function was deprecated as of CUDA 5.0 and its functionality superseded
  * by ::cuDeviceGetAttribute(). 
  *
  * Returns in \p *major and \p *minor the major and minor revision numbers that
@@ -2632,7 +2632,7 @@ CUresult CUDAAPI cuDevicePrimaryCtxRelea
 /**
  * \brief Set flags for the primary context
  *
- * Sets the flags for the primary context on the device overwriting perviously
+ * Sets the flags for the primary context on the device overwriting previously
  * set ones. If the primary context is already created
  * ::CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE is returned.
  *
@@ -4572,7 +4572,7 @@ CUresult CUDAAPI cuMemHostGetFlags(unsig
  * ::cuStreamAttachMemAsync will be required to enable access on such devices.
  *
  * If the association is later changed via ::cuStreamAttachMemAsync to
- * a single stream, the default association as specifed during ::cuMemAllocManaged
+ * a single stream, the default association as specified during ::cuMemAllocManaged
  * is restored when that stream is destroyed. For __managed__ variables, the
  * default association is always ::CU_MEM_ATTACH_GLOBAL. Note that destroying a
  * stream is an asynchronous operation, and as a result, the change to default
@@ -4903,7 +4903,7 @@ CUresult CUDAAPI cuIpcOpenMemHandle(CUde
 /**
  * \brief Close memory mapped with ::cuIpcOpenMemHandle
  * 
- * Unmaps memory returnd by ::cuIpcOpenMemHandle. The original allocation
+ * Unmaps memory returned by ::cuIpcOpenMemHandle. The original allocation
  * in the exporting process as well as imported mappings in other processes
  * will be unaffected.
  *
@@ -9642,7 +9642,7 @@ CUresult CUDAAPI cuLaunchCooperativeKern
  * All kernels launched must be identical with respect to the compiled code. Note that
  * any __device__, __constant__ or __managed__ variables present in the module that owns
  * the kernel launched on each device, are independently instantiated on every device.
- * It is the application's responsiblity to ensure these variables are initialized and
+ * It is the application's responsibility to ensure these variables are initialized and
  * used appropriately.
  *
  * The size of the grids as specified in blocks, the size of the blocks themselves
--- a/nvidia-cuda/include/cuda_runtime.h
+++ b/nvidia-cuda/include/cuda_runtime.h
@@ -159,8 +159,8 @@ struct  __device_builtin__ __nv_lambda_p
  * \p stream specifies a stream the invocation is associated to.
  *
  * \param func        - Device function symbol
- * \param gridDim     - Grid dimentions
- * \param blockDim    - Block dimentions
+ * \param gridDim     - Grid dimensions
+ * \param blockDim    - Block dimensions
  * \param args        - Arguments
  * \param sharedMem   - Shared memory (defaults to 0)
  * \param stream      - Stream identifier (defaults to NULL)
@@ -222,8 +222,8 @@ static __inline__ __host__ cudaError_t c
  * \p stream specifies a stream the invocation is associated to.
  *
  * \param func        - Device function symbol
- * \param gridDim     - Grid dimentions
- * \param blockDim    - Block dimentions
+ * \param gridDim     - Grid dimensions
+ * \param blockDim    - Block dimensions
  * \param args        - Arguments
  * \param sharedMem   - Shared memory (defaults to 0)
  * \param stream      - Stream identifier (defaults to NULL)
@@ -434,7 +434,7 @@ static __inline__ __host__ cudaError_t c
  * ::cudaStreamAttachMemAsync will be required to enable access on such devices.
  *
  * If the association is later changed via ::cudaStreamAttachMemAsync to
- * a single stream, the default association, as specifed during ::cudaMallocManaged,
+ * a single stream, the default association, as specified during ::cudaMallocManaged,
  * is restored when that stream is destroyed. For __managed__ variables, the
  * default association is always ::cudaMemAttachGlobal. Note that destroying a
  * stream is an asynchronous operation, and as a result, the change to default
@@ -1392,7 +1392,7 @@ static __inline__ __host__ cudaError_t c
  * streaming multiprocessor for the device function.
  *
  * \param numBlocks       - Returned occupancy
- * \param func            - Kernel function for which occupancy is calulated
+ * \param func            - Kernel function for which occupancy is calculated
  * \param blockSize       - Block size the kernel is intended to be launched with
  * \param dynamicSMemSize - Per-block dynamic shared memory usage intended, in bytes
  *
@@ -1442,7 +1442,7 @@ static __inline__ __host__ cudaError_t c
  *   section of the Maxwell tuning guide.
  *
  * \param numBlocks       - Returned occupancy
- * \param func            - Kernel function for which occupancy is calulated
+ * \param func            - Kernel function for which occupancy is calculated
  * \param blockSize       - Block size the kernel is intended to be launched with
  * \param dynamicSMemSize - Per-block dynamic shared memory usage intended, in bytes
  * \param flags           - Requested behavior for the occupancy calculator
@@ -1784,7 +1784,7 @@ static __inline__ __host__ CUDART_DEVICE
 }
 
 /**
- * \brief Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags
+ * \brief Returns grid and block size that achieved maximum potential occupancy for a device function with the specified flags
  *
  * Returns in \p *minGridSize and \p *blocksize a suggested grid /
  * block size pair that achieves the best potential occupancy
--- a/nvidia-cuda/include/cuda_runtime_api.h
+++ b/nvidia-cuda/include/cuda_runtime_api.h
@@ -357,7 +357,7 @@ extern __host__ cudaError_t CUDARTAPI cu
  * - ::cudaLimitMallocHeapSize: size in bytes of the heap used by the
  *   ::malloc() and ::free() device system calls;
  * - ::cudaLimitDevRuntimeSyncDepth: maximum grid depth at which a
- *   thread can isssue the device runtime call ::cudaDeviceSynchronize()
+ *   thread can issue the device runtime call ::cudaDeviceSynchronize()
  *   to wait on child grid launches to complete.
  * - ::cudaLimitDevRuntimePendingLaunchCount: maximum number of outstanding
  *   device runtime launches.
@@ -794,7 +794,7 @@ extern __host__ cudaError_t CUDARTAPI cu
 /**
  * \brief Close memory mapped with cudaIpcOpenMemHandle
  * 
- * Unmaps memory returnd by ::cudaIpcOpenMemHandle. The original allocation
+ * Unmaps memory returned by ::cudaIpcOpenMemHandle. The original allocation
  * in the exporting process as well as imported mappings in other processes
  * will be unaffected.
  *
@@ -2593,8 +2593,8 @@ extern __host__ cudaError_t CUDARTAPI cu
  * \p stream specifies a stream the invocation is associated to.
  *
  * \param func        - Device function symbol
- * \param gridDim     - Grid dimentions
- * \param blockDim    - Block dimentions
+ * \param gridDim     - Grid dimensions
+ * \param blockDim    - Block dimensions
  * \param args        - Arguments
  * \param sharedMem   - Shared memory
  * \param stream      - Stream identifier
@@ -2649,8 +2649,8 @@ extern __host__ cudaError_t CUDARTAPI cu
  * \p stream specifies a stream the invocation is associated to.
  *
  * \param func        - Device function symbol
- * \param gridDim     - Grid dimentions
- * \param blockDim    - Block dimentions
+ * \param gridDim     - Grid dimensions
+ * \param blockDim    - Block dimensions
  * \param args        - Arguments
  * \param sharedMem   - Shared memory
  * \param stream      - Stream identifier
@@ -2688,7 +2688,7 @@ extern __host__ cudaError_t CUDARTAPI cu
  *
  * The same kernel must be launched on all devices. Note that any __device__ or __constant__
  * variables are independently instantiated on every device. It is the application's
- * responsiblity to ensure these variables are initialized and used appropriately.
+ * responsibility to ensure these variables are initialized and used appropriately.
  *
  * The size of the grids as specified in blocks, the size of the blocks themselves and the
  * amount of shared memory used by each thread block must also match across all launched kernels.
@@ -3255,7 +3255,7 @@ extern __host__ cudaError_t CUDARTAPI cu
  * ::cudaStreamAttachMemAsync will be required to enable access on such devices.
  *
  * If the association is later changed via ::cudaStreamAttachMemAsync to
- * a single stream, the default association, as specifed during ::cudaMallocManaged,
+ * a single stream, the default association, as specified during ::cudaMallocManaged,
  * is restored when that stream is destroyed. For __managed__ variables, the
  * default association is always ::cudaMemAttachGlobal. Note that destroying a
  * stream is an asynchronous operation, and as a result, the change to default
@@ -4168,7 +4168,7 @@ struct cudaMemcpy3DParms {
 };
 \endcode
  *
- * ::cudaMemcpy3D() copies data betwen two 3D objects. The source and
+ * ::cudaMemcpy3D() copies data between two 3D objects. The source and
  * destination objects may be in either host memory, device memory, or a CUDA
  * array. The source, destination, extent, and kind of copy performed is
  * specified by the ::cudaMemcpy3DParms struct which should be initialized to
@@ -4300,7 +4300,7 @@ struct cudaMemcpy3DParms {
 };
 \endcode
  *
- * ::cudaMemcpy3DAsync() copies data betwen two 3D objects. The source and
+ * ::cudaMemcpy3DAsync() copies data between two 3D objects. The source and
  * destination objects may be in either host memory, device memory, or a CUDA
  * array. The source, destination, extent, and kind of copy performed is
  * specified by the ::cudaMemcpy3DParms struct which should be initialized to
--- a/nvidia-cuda/doc/html/cuda-driver-api/group__CUDA__MEM.html
+++ b/nvidia-cuda/doc/html/cuda-driver-api/group__CUDA__MEM.html
@@ -961,7 +961,7 @@
                            </div>
                            <div class="section">
                               <h6 class="description_header">Description</h6>
-                              <p>Unmaps memory returnd by <a class="xref" href="group__CUDA__MEM.html#group__CUDA__MEM_1ga8bd126fcff919a0c996b7640f197b79" title="Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process." shape="rect">cuIpcOpenMemHandle</a>. The original allocation in the exporting process as well as imported mappings in other processes will be unaffected.
+                              <p>Unmaps memory returned by <a class="xref" href="group__CUDA__MEM.html#group__CUDA__MEM_1ga8bd126fcff919a0c996b7640f197b79" title="Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process." shape="rect">cuIpcOpenMemHandle</a>. The original allocation in the exporting process as well as imported mappings in other processes will be unaffected.
                               </p>
                               <p class="p">Any resources used to enable peer access will be freed if this is the last mapping using them.</p>
                               <p class="p">IPC functionality is restricted to devices with support for unified addressing on Linux and Windows operating systems. IPC
@@ -1247,7 +1247,7 @@
                               </p>
                               <p class="p"><tt class="ph tt code">flags</tt> specifies the default stream association for this allocation. <tt class="ph tt code">flags</tt> must be one of <a class="xref" href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gg17c5d5f9b585aa2d6f121847d1a78f4c0b42aae6a29b41b734d4c0dea6c33313" shape="rect">CU_MEM_ATTACH_GLOBAL</a> or <a class="xref" href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gg17c5d5f9b585aa2d6f121847d1a78f4c8b59c62cab9c7a762338e5fae92e2e9c" shape="rect">CU_MEM_ATTACH_HOST</a>. If <a class="xref" href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gg17c5d5f9b585aa2d6f121847d1a78f4c0b42aae6a29b41b734d4c0dea6c33313" shape="rect">CU_MEM_ATTACH_GLOBAL</a> is specified, then this memory is accessible from any stream on any device. If <a class="xref" href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gg17c5d5f9b585aa2d6f121847d1a78f4c8b59c62cab9c7a762338e5fae92e2e9c" shape="rect">CU_MEM_ATTACH_HOST</a> is specified, then the allocation should not be accessed from devices that have a zero value for the device attribute <a class="xref" href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gge12b8a782bebe21b1ac0091bf9f4e2a333110e44c9cb6ead02f03ff6f6fd495e" shape="rect">CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS</a>; an explicit call to <a class="xref" href="group__CUDA__STREAM.html#group__CUDA__STREAM_1g6e468d680e263e7eba02a56643c50533" title="Attach memory to a stream asynchronously." shape="rect">cuStreamAttachMemAsync</a> will be required to enable access on such devices.
                               </p>
-                              <p class="p">If the association is later changed via <a class="xref" href="group__CUDA__STREAM.html#group__CUDA__STREAM_1g6e468d680e263e7eba02a56643c50533" title="Attach memory to a stream asynchronously." shape="rect">cuStreamAttachMemAsync</a> to a single stream, the default association as specifed during <a class="xref" href="group__CUDA__MEM.html#group__CUDA__MEM_1gb347ded34dc326af404aa02af5388a32" title="Allocates memory that will be automatically managed by the Unified Memory system." shape="rect">cuMemAllocManaged</a> is restored when that stream is destroyed. For __managed__ variables, the default association is always <a class="xref" href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gg17c5d5f9b585aa2d6f121847d1a78f4c0b42aae6a29b41b734d4c0dea6c33313" shape="rect">CU_MEM_ATTACH_GLOBAL</a>. Note that destroying a stream is an asynchronous operation, and as a result, the change to default association won't happen
+                              <p class="p">If the association is later changed via <a class="xref" href="group__CUDA__STREAM.html#group__CUDA__STREAM_1g6e468d680e263e7eba02a56643c50533" title="Attach memory to a stream asynchronously." shape="rect">cuStreamAttachMemAsync</a> to a single stream, the default association as specified during <a class="xref" href="group__CUDA__MEM.html#group__CUDA__MEM_1gb347ded34dc326af404aa02af5388a32" title="Allocates memory that will be automatically managed by the Unified Memory system." shape="rect">cuMemAllocManaged</a> is restored when that stream is destroyed. For __managed__ variables, the default association is always <a class="xref" href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gg17c5d5f9b585aa2d6f121847d1a78f4c0b42aae6a29b41b734d4c0dea6c33313" shape="rect">CU_MEM_ATTACH_GLOBAL</a>. Note that destroying a stream is an asynchronous operation, and as a result, the change to default association won't happen
                                  until all work in the stream has completed.
                               </p>
                               <p class="p">Memory allocated with <a class="xref" href="group__CUDA__MEM.html#group__CUDA__MEM_1gb347ded34dc326af404aa02af5388a32" title="Allocates memory that will be automatically managed by the Unified Memory system." shape="rect">cuMemAllocManaged</a> should be released with <a class="xref" href="group__CUDA__MEM.html#group__CUDA__MEM_1g89b3f154e17cc89b6eea277dbdf5c93a" title="Frees device memory." shape="rect">cuMemFree</a>.
--- a/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__DEVICE.html
+++ b/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__DEVICE.html
@@ -967,7 +967,7 @@
                                        </p>
                                     </li>
                                     <li class="li">
-                                       <p class="p"><a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc9365123c4900be4af436cb769e4c72d07be11" shape="rect">cudaLimitDevRuntimeSyncDepth</a>: maximum grid depth at which a thread can isssue the device runtime call <a class="xref" href="group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" title="Wait for compute device to finish." shape="rect">cudaDeviceSynchronize()</a> to wait on child grid launches to complete.
+                                       <p class="p"><a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc9365123c4900be4af436cb769e4c72d07be11" shape="rect">cudaLimitDevRuntimeSyncDepth</a>: maximum grid depth at which a thread can issue the device runtime call <a class="xref" href="group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" title="Wait for compute device to finish." shape="rect">cudaDeviceSynchronize()</a> to wait on child grid launches to complete.
                                        </p>
                                     </li>
                                     <li class="li">
@@ -1995,7 +1995,7 @@
                            </div>
                            <div class="section">
                               <h6 class="description_header">Description</h6>
-                              <p>Unmaps memory returnd by <a class="xref" href="group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9" title="Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process." shape="rect">cudaIpcOpenMemHandle</a>. The original allocation in the exporting process as well as imported mappings in other processes will be unaffected.
+                              <p>Unmaps memory returned by <a class="xref" href="group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9" title="Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process." shape="rect">cudaIpcOpenMemHandle</a>. The original allocation in the exporting process as well as imported mappings in other processes will be unaffected.
                               </p>
                               <p class="p">Any resources used to enable peer access will be freed if this is the last mapping using them.</p>
                               <p class="p">IPC functionality is restricted to devices with support for unified addressing on Linux operating systems. IPC functionality
--- a/nvidia-cuda/doc/man/man3/CUDART_DEVICE.3
+++ b/nvidia-cuda/doc/man/man3/CUDART_DEVICE.3
@@ -444,7 +444,7 @@ Returns in \fC*pValue\fP the current siz
 .IP "\(bu" 2
 \fBcudaLimitMallocHeapSize\fP: size in bytes of the heap used by the malloc() and free() device system calls;
 .IP "\(bu" 2
-\fBcudaLimitDevRuntimeSyncDepth\fP: maximum grid depth at which a thread can isssue the device runtime call \fBcudaDeviceSynchronize()\fP to wait on child grid launches to complete.
+\fBcudaLimitDevRuntimeSyncDepth\fP: maximum grid depth at which a thread can issue the device runtime call \fBcudaDeviceSynchronize()\fP to wait on child grid launches to complete.
 .IP "\(bu" 2
 \fBcudaLimitDevRuntimePendingLaunchCount\fP: maximum number of outstanding device runtime launches.
 .PP
@@ -1109,7 +1109,7 @@ cudaComputeModeExclusiveProcess: Compute
 
 .SS "\fBcudaError_t\fP cudaIpcCloseMemHandle (void * devPtr)"
 .PP
-Unmaps memory returnd by \fBcudaIpcOpenMemHandle\fP. The original allocation in the exporting process as well as imported mappings in other processes will be unaffected.
+Unmaps memory returned by \fBcudaIpcOpenMemHandle\fP. The original allocation in the exporting process as well as imported mappings in other processes will be unaffected.
 .PP
 Any resources used to enable peer access will be freed if this is the last mapping using them.
 .PP
--- a/nvidia-cuda/doc/html/cublas/index.html
+++ b/nvidia-cuda/doc/html/cublas/index.html
@@ -32659,7 +32659,7 @@ cublasXtDestroy(cublasXtHandle_t handle)
                               When enabled, the matrices passed in subsequent  cublasXt API calls will be pinned/unpinned using the CUDART routine <samp class="ph codeph">cudaHostRegister</samp> and 
                               <samp class="ph codeph">cudaHostUnregister</samp> respectively if the matrices are not already pinned. 
                               If a matrix happened to be pinned partially, it will also not be pinned.
-                              Pinning the memory improve PCI transfer performace and allows to overlap PCI memory transfer with computation. However pinning/unpinning
+                              Pinning the memory improve PCI transfer performace and allows one to overlap PCI memory transfer with computation. However pinning/unpinning
                               the memory take some time which might not be amortized.
                               It is advised that the user pins the memory on its own using <samp class="ph codeph">cudaMallocHost</samp> or <samp class="ph codeph">cudaHostRegister</samp> and unpin it when the computation sequence is completed.
                               By default, the Pinning Memory mode is disabled.
--- a/nvidia-cuda/doc/html/cuda-driver-api/group__CUDA__DEVICE.html
+++ b/nvidia-cuda/doc/html/cuda-driver-api/group__CUDA__DEVICE.html
@@ -280,7 +280,7 @@
                      <dt><span class="member_type"><a href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gc6c391505e117393cc2558fff6bfc2e9" title="" shape="rect">CUresult</a>&nbsp;</span><span class="member_name"><a href="#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74" shape="rect">cuDeviceGetCount</a> (  int*<span>&nbsp;</span><span class="keyword keyword apiItemName">count</span> ) </span></dt>
                      <dd class="shortdesc"><span></span><span class="desc">Returns the number of compute-capable devices. </span></dd>
                      <dt><span class="member_type"><a href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gc6c391505e117393cc2558fff6bfc2e9" title="" shape="rect">CUresult</a>&nbsp;</span><span class="member_name"><a href="#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" shape="rect">cuDeviceGetName</a> (  char*<span>&nbsp;</span><span class="keyword keyword apiItemName">name</span>, int <span>&nbsp;</span><span class="keyword keyword apiItemName">len</span>, <a href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gcd81b70eb9968392bb5cdf582af8eab4" title="" shape="rect">CUdevice</a><span>&nbsp;</span><span class="keyword keyword apiItemName">dev</span> ) </span></dt>
-                     <dd class="shortdesc"><span></span><span class="desc">Returns an identifer string for the device. </span></dd>
+                     <dd class="shortdesc"><span></span><span class="desc">Returns an identifier string for the device. </span></dd>
                      <dt><span class="member_type"><a href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gc6c391505e117393cc2558fff6bfc2e9" title="" shape="rect">CUresult</a>&nbsp;</span><span class="member_name"><a href="#group__CUDA__DEVICE_1g987b46b884c101ed5be414ab4d9e60e4" shape="rect">cuDeviceGetUuid</a> (  CUuuid*<span>&nbsp;</span><span class="keyword keyword apiItemName">uuid</span>, <a href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gcd81b70eb9968392bb5cdf582af8eab4" title="" shape="rect">CUdevice</a><span>&nbsp;</span><span class="keyword keyword apiItemName">dev</span> ) </span></dt>
                      <dd class="shortdesc"><span></span><span class="desc">Return an UUID for the device. </span></dd>
                      <dt><span class="member_type"><a href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gc6c391505e117393cc2558fff6bfc2e9" title="" shape="rect">CUresult</a>&nbsp;</span><span class="member_name"><a href="#group__CUDA__DEVICE_1gc6a0d6551335a3780f9f3c967a0fde5d" shape="rect">cuDeviceTotalMem</a> (  size_t*<span>&nbsp;</span><span class="keyword keyword apiItemName">bytes</span>, <a href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gcd81b70eb9968392bb5cdf582af8eab4" title="" shape="rect">CUdevice</a><span>&nbsp;</span><span class="keyword keyword apiItemName">dev</span> ) </span></dt>
@@ -321,7 +321,7 @@
                               </p>
                               <p class="p"></p>
                               <p class="p apiDesc_subtitle"><strong class="ph b">See also:</strong></p>
-                              <p class="p see_subsection"><a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" title="Returns information about the device." shape="rect">cuDeviceGetAttribute</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74" title="Returns the number of compute-capable devices." shape="rect">cuDeviceGetCount</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" title="Returns an identifer string for the device." shape="rect">cuDeviceGetName</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g987b46b884c101ed5be414ab4d9e60e4" title="Return an UUID for the device." shape="rect">cuDeviceGetUuid</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gc6a0d6551335a3780f9f3c967a0fde5d" title="Returns the total amount of memory on the device." shape="rect">cuDeviceTotalMem</a></p>
+                              <p class="p see_subsection"><a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" title="Returns information about the device." shape="rect">cuDeviceGetAttribute</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74" title="Returns the number of compute-capable devices." shape="rect">cuDeviceGetCount</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" title="Returns an identifier string for the device." shape="rect">cuDeviceGetName</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g987b46b884c101ed5be414ab4d9e60e4" title="Return an UUID for the device." shape="rect">cuDeviceGetUuid</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gc6a0d6551335a3780f9f3c967a0fde5d" title="Returns the total amount of memory on the device." shape="rect">cuDeviceTotalMem</a></p>
                               <p class="p"></p>
                            </div>
                         </dd>
@@ -695,7 +695,7 @@
                                        </p>
                                     </li>
                                     <li class="li">
-                                       <p class="p"><a class="xref" href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gge12b8a782bebe21b1ac0091bf9f4e2a35fdcdbe1dfc3ad5ec428c279e0efb9cd" shape="rect">CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS</a>: Device suppports coherently accessing pageable memory without calling cudaHostRegister on it.
+                                       <p class="p"><a class="xref" href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gge12b8a782bebe21b1ac0091bf9f4e2a35fdcdbe1dfc3ad5ec428c279e0efb9cd" shape="rect">CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS</a>: Device supports coherently accessing pageable memory without calling cudaHostRegister on it.
                                        </p>
                                     </li>
                                     <li class="li">
@@ -711,7 +711,7 @@
                                        </p>
                                     </li>
                                     <li class="li">
-                                       <p class="p"><a class="xref" href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gge12b8a782bebe21b1ac0091bf9f4e2a3e788564c0a95b866dc624fbc1b49dab3" shape="rect">CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK_OPTIN</a>: The maximum per block shared memory size suported on this device. This is the maximum value that can be opted into when
+                                       <p class="p"><a class="xref" href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gge12b8a782bebe21b1ac0091bf9f4e2a3e788564c0a95b866dc624fbc1b49dab3" shape="rect">CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK_OPTIN</a>: The maximum per block shared memory size supported on this device. This is the maximum value that can be opted into when
                                           using the <a class="xref" href="group__CUDA__EXEC.html#group__CUDA__EXEC_1g0e37dce0173bc883aa1e5b14dd747f26" title="Sets information about a function." shape="rect">cuFuncSetAttribute()</a> call. For more details see <a class="xref" href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gg9d955dde0904a9b43ca4d875ac1551bc75b33d145e83462ef7292575015be03e" shape="rect">CU_FUNC_ATTRIBUTE_MAX_DYNAMIC_SHARED_SIZE_BYTES</a></p>
                                     </li>
                                     <li class="li">
@@ -732,7 +732,7 @@
                               </p>
                               <p class="p"></p>
                               <p class="p apiDesc_subtitle"><strong class="ph b">See also:</strong></p>
-                              <p class="p see_subsection"><a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74" title="Returns the number of compute-capable devices." shape="rect">cuDeviceGetCount</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" title="Returns an identifer string for the device." shape="rect">cuDeviceGetName</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g987b46b884c101ed5be414ab4d9e60e4" title="Return an UUID for the device." shape="rect">cuDeviceGetUuid</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g8bdd1cc7201304b01357b8034f6587cb" title="Returns a handle to a compute device." shape="rect">cuDeviceGet</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gc6a0d6551335a3780f9f3c967a0fde5d" title="Returns the total amount of memory on the device." shape="rect">cuDeviceTotalMem</a>, <a class="xref" href="../cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gb22e8256592b836df9a9cc36c9db7151" target="_blank" shape="rect">cudaDeviceGetAttribute</a>, <a class="xref" href="../cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" target="_blank" shape="rect">cudaGetDeviceProperties</a></p>
+                              <p class="p see_subsection"><a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74" title="Returns the number of compute-capable devices." shape="rect">cuDeviceGetCount</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" title="Returns an identifier string for the device." shape="rect">cuDeviceGetName</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g987b46b884c101ed5be414ab4d9e60e4" title="Return an UUID for the device." shape="rect">cuDeviceGetUuid</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g8bdd1cc7201304b01357b8034f6587cb" title="Returns a handle to a compute device." shape="rect">cuDeviceGet</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gc6a0d6551335a3780f9f3c967a0fde5d" title="Returns the total amount of memory on the device." shape="rect">cuDeviceTotalMem</a>, <a class="xref" href="../cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gb22e8256592b836df9a9cc36c9db7151" target="_blank" shape="rect">cudaDeviceGetAttribute</a>, <a class="xref" href="../cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" target="_blank" shape="rect">cudaGetDeviceProperties</a></p>
                               <p class="p"></p>
                            </div>
                         </dd>
@@ -767,14 +767,14 @@
                               </p>
                               <p class="p"></p>
                               <p class="p apiDesc_subtitle"><strong class="ph b">See also:</strong></p>
-                              <p class="p see_subsection"><a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" title="Returns information about the device." shape="rect">cuDeviceGetAttribute</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" title="Returns an identifer string for the device." shape="rect">cuDeviceGetName</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g987b46b884c101ed5be414ab4d9e60e4" title="Return an UUID for the device." shape="rect">cuDeviceGetUuid</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g8bdd1cc7201304b01357b8034f6587cb" title="Returns a handle to a compute device." shape="rect">cuDeviceGet</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gc6a0d6551335a3780f9f3c967a0fde5d" title="Returns the total amount of memory on the device." shape="rect">cuDeviceTotalMem</a>, <a class="xref" href="../cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f" target="_blank" shape="rect">cudaGetDeviceCount</a></p>
+                              <p class="p see_subsection"><a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" title="Returns information about the device." shape="rect">cuDeviceGetAttribute</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" title="Returns an identifier string for the device." shape="rect">cuDeviceGetName</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g987b46b884c101ed5be414ab4d9e60e4" title="Return an UUID for the device." shape="rect">cuDeviceGetUuid</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g8bdd1cc7201304b01357b8034f6587cb" title="Returns a handle to a compute device." shape="rect">cuDeviceGet</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gc6a0d6551335a3780f9f3c967a0fde5d" title="Returns the total amount of memory on the device." shape="rect">cuDeviceTotalMem</a>, <a class="xref" href="../cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f" target="_blank" shape="rect">cudaGetDeviceCount</a></p>
                               <p class="p"></p>
                            </div>
                         </dd>
                         <dt class="description"><a name="group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" id="group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" shape="rect">
                               <!-- --></a><span><a href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gc6c391505e117393cc2558fff6bfc2e9" title="" shape="rect">CUresult</a> cuDeviceGetName (  char*<span>&nbsp;</span><span class="keyword keyword apiItemName">name</span>, int <span>&nbsp;</span><span class="keyword keyword apiItemName">len</span>, <a href="group__CUDA__TYPES.html#group__CUDA__TYPES_1gcd81b70eb9968392bb5cdf582af8eab4" title="" shape="rect">CUdevice</a><span>&nbsp;</span><span class="keyword keyword apiItemName">dev</span> ) </span></dt>
                         <dd class="description">
-                           <div class="section">Returns an identifer string for the device. </div>
+                           <div class="section">Returns an identifier string for the device. </div>
                            <div class="section">
                               <h6 class="parameter_header">
                                  Parameters
@@ -841,7 +841,7 @@
                               </p>
                               <p class="p"></p>
                               <p class="p apiDesc_subtitle"><strong class="ph b">See also:</strong></p>
-                              <p class="p see_subsection"><a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" title="Returns information about the device." shape="rect">cuDeviceGetAttribute</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74" title="Returns the number of compute-capable devices." shape="rect">cuDeviceGetCount</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" title="Returns an identifer string for the device." shape="rect">cuDeviceGetName</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g8bdd1cc7201304b01357b8034f6587cb" title="Returns a handle to a compute device." shape="rect">cuDeviceGet</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gc6a0d6551335a3780f9f3c967a0fde5d" title="Returns the total amount of memory on the device." shape="rect">cuDeviceTotalMem</a>, <a class="xref" href="../cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" target="_blank" shape="rect">cudaGetDeviceProperties</a></p>
+                              <p class="p see_subsection"><a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" title="Returns information about the device." shape="rect">cuDeviceGetAttribute</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74" title="Returns the number of compute-capable devices." shape="rect">cuDeviceGetCount</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" title="Returns an identifier string for the device." shape="rect">cuDeviceGetName</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g8bdd1cc7201304b01357b8034f6587cb" title="Returns a handle to a compute device." shape="rect">cuDeviceGet</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gc6a0d6551335a3780f9f3c967a0fde5d" title="Returns the total amount of memory on the device." shape="rect">cuDeviceTotalMem</a>, <a class="xref" href="../cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" target="_blank" shape="rect">cudaGetDeviceProperties</a></p>
                               <p class="p"></p>
                            </div>
                         </dd>
@@ -877,7 +877,7 @@
                               </p>
                               <p class="p"></p>
                               <p class="p apiDesc_subtitle"><strong class="ph b">See also:</strong></p>
-                              <p class="p see_subsection"><a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" title="Returns information about the device." shape="rect">cuDeviceGetAttribute</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74" title="Returns the number of compute-capable devices." shape="rect">cuDeviceGetCount</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" title="Returns an identifer string for the device." shape="rect">cuDeviceGetName</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g987b46b884c101ed5be414ab4d9e60e4" title="Return an UUID for the device." shape="rect">cuDeviceGetUuid</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g8bdd1cc7201304b01357b8034f6587cb" title="Returns a handle to a compute device." shape="rect">cuDeviceGet</a>, <a class="xref" href="../cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g376b97f5ab20321ca46f7cfa9511b978" target="_blank" shape="rect">cudaMemGetInfo</a></p>
+                              <p class="p see_subsection"><a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" title="Returns information about the device." shape="rect">cuDeviceGetAttribute</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74" title="Returns the number of compute-capable devices." shape="rect">cuDeviceGetCount</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" title="Returns an identifier string for the device." shape="rect">cuDeviceGetName</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g987b46b884c101ed5be414ab4d9e60e4" title="Return an UUID for the device." shape="rect">cuDeviceGetUuid</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g8bdd1cc7201304b01357b8034f6587cb" title="Returns a handle to a compute device." shape="rect">cuDeviceGet</a>, <a class="xref" href="../cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g376b97f5ab20321ca46f7cfa9511b978" target="_blank" shape="rect">cudaMemGetInfo</a></p>
                               <p class="p"></p>
                            </div>
                         </dd>
@@ -894,4 +894,4 @@
       <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-write.js"></script>
       <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-tracker.js"></script>
       <script type="text/javascript">var switchTo5x=true;</script><script type="text/javascript" src="http://w.sharethis.com/button/buttons.js"></script><script type="text/javascript">stLight.options({publisher: "998dc202-a267-4d8e-bce9-14debadb8d92", doNotHash: false, doNotCopy: false, hashAddressBar: false});</script><script type="text/javascript">_satellite.pageBottom();</script></body>
-</html>
\ No newline at end of file
+</html>
--- a/nvidia-cuda/doc/html/cuda-driver-api/group__CUDA__DEVICE__DEPRECATED.html
+++ b/nvidia-cuda/doc/html/cuda-driver-api/group__CUDA__DEVICE__DEPRECATED.html
@@ -305,7 +305,7 @@
                            </div>
                            <div class="section">
                               <h6 class="deprecated_header"><a class="xref xrefsect-title" href="deprecated.html#deprecated__deprecated_1_deprecated000002" shape="rect">Deprecated</a></h6>
-                              <p>This function was deprecated as of CUDA 5.0 and its functionality superceded by <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" title="Returns information about the device." shape="rect">cuDeviceGetAttribute()</a>.
+                              <p>This function was deprecated as of CUDA 5.0 and its functionality superseded by <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" title="Returns information about the device." shape="rect">cuDeviceGetAttribute()</a>.
                               </p>
                               <h6 class="description_header">Description</h6>
                               <p class="p">Returns in <tt class="ph tt code">*major</tt> and <tt class="ph tt code">*minor</tt> the major and minor revision numbers that define the compute capability of the device <tt class="ph tt code">dev</tt>.
@@ -318,7 +318,7 @@
                               </p>
                               <p class="p"></p>
                               <p class="p apiDesc_subtitle"><strong class="ph b">See also:</strong></p>
-                              <p class="p see_subsection"><a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" title="Returns information about the device." shape="rect">cuDeviceGetAttribute</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74" title="Returns the number of compute-capable devices." shape="rect">cuDeviceGetCount</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" title="Returns an identifer string for the device." shape="rect">cuDeviceGetName</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g987b46b884c101ed5be414ab4d9e60e4" title="Return an UUID for the device." shape="rect">cuDeviceGetUuid</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g8bdd1cc7201304b01357b8034f6587cb" title="Returns a handle to a compute device." shape="rect">cuDeviceGet</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gc6a0d6551335a3780f9f3c967a0fde5d" title="Returns the total amount of memory on the device." shape="rect">cuDeviceTotalMem</a></p>
+                              <p class="p see_subsection"><a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" title="Returns information about the device." shape="rect">cuDeviceGetAttribute</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74" title="Returns the number of compute-capable devices." shape="rect">cuDeviceGetCount</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" title="Returns an identifier string for the device." shape="rect">cuDeviceGetName</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g987b46b884c101ed5be414ab4d9e60e4" title="Return an UUID for the device." shape="rect">cuDeviceGetUuid</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g8bdd1cc7201304b01357b8034f6587cb" title="Returns a handle to a compute device." shape="rect">cuDeviceGet</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gc6a0d6551335a3780f9f3c967a0fde5d" title="Returns the total amount of memory on the device." shape="rect">cuDeviceTotalMem</a></p>
                               <p class="p"></p>
                            </div>
                         </dd>
@@ -406,7 +406,7 @@
                               </p>
                               <p class="p"></p>
                               <p class="p apiDesc_subtitle"><strong class="ph b">See also:</strong></p>
-                              <p class="p see_subsection"><a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" title="Returns information about the device." shape="rect">cuDeviceGetAttribute</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74" title="Returns the number of compute-capable devices." shape="rect">cuDeviceGetCount</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" title="Returns an identifer string for the device." shape="rect">cuDeviceGetName</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g987b46b884c101ed5be414ab4d9e60e4" title="Return an UUID for the device." shape="rect">cuDeviceGetUuid</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g8bdd1cc7201304b01357b8034f6587cb" title="Returns a handle to a compute device." shape="rect">cuDeviceGet</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gc6a0d6551335a3780f9f3c967a0fde5d" title="Returns the total amount of memory on the device." shape="rect">cuDeviceTotalMem</a></p>
+                              <p class="p see_subsection"><a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" title="Returns information about the device." shape="rect">cuDeviceGetAttribute</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74" title="Returns the number of compute-capable devices." shape="rect">cuDeviceGetCount</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" title="Returns an identifier string for the device." shape="rect">cuDeviceGetName</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g987b46b884c101ed5be414ab4d9e60e4" title="Return an UUID for the device." shape="rect">cuDeviceGetUuid</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g8bdd1cc7201304b01357b8034f6587cb" title="Returns a handle to a compute device." shape="rect">cuDeviceGet</a>, <a class="xref" href="group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gc6a0d6551335a3780f9f3c967a0fde5d" title="Returns the total amount of memory on the device." shape="rect">cuDeviceTotalMem</a></p>
                               <p class="p"></p>
                            </div>
                         </dd>
@@ -423,4 +423,4 @@
       <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-write.js"></script>
       <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-tracker.js"></script>
       <script type="text/javascript">var switchTo5x=true;</script><script type="text/javascript" src="http://w.sharethis.com/button/buttons.js"></script><script type="text/javascript">stLight.options({publisher: "998dc202-a267-4d8e-bce9-14debadb8d92", doNotHash: false, doNotCopy: false, hashAddressBar: false});</script><script type="text/javascript">_satellite.pageBottom();</script></body>
-</html>
\ No newline at end of file
+</html>
--- a/nvidia-cuda/doc/html/cuda-driver-api/group__CUDA__EGL.html
+++ b/nvidia-cuda/doc/html/cuda-driver-api/group__CUDA__EGL.html
@@ -420,7 +420,7 @@
                               </h6>
                               <dl class="table-display-params">
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">conn</span></tt></dt>
-                                 <dd>- Conection to disconnect.</dd>
+                                 <dd>- Connection to disconnect.</dd>
                               </dl>
                            </div>
                            <div class="section">
@@ -522,7 +522,7 @@
                               </h6>
                               <dl class="table-display-params">
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">conn</span></tt></dt>
-                                 <dd>- Conection to disconnect.</dd>
+                                 <dd>- Connection to disconnect.</dd>
                               </dl>
                            </div>
                            <div class="section">
@@ -701,7 +701,7 @@
                                  operation which access the objects have completed before passing control to CUDA. This may be accomplished by issuing and
                                  waiting for glFinish command on all GLcontexts (for OpenGL and likewise for other APIs). The application will be also responsible
                                  for ensuring that any pending operation on the registered CUDA resource has completed prior to executing subsequent commands
-                                 in other APIs accesing the same memory objects. This can be accomplished by calling cuCtxSynchronize or cuEventSynchronize
+                                 in other APIs accessing the same memory objects. This can be accomplished by calling cuCtxSynchronize or cuEventSynchronize
                                  (preferably).
                               </p>
                               <p class="p">The surface's intended usage is specified using <tt class="ph tt code">flags</tt>, as follows:
--- a/nvidia-cuda/doc/html/cuda-driver-api/group__CUDA__EXEC.html
+++ b/nvidia-cuda/doc/html/cuda-driver-api/group__CUDA__EXEC.html
@@ -666,7 +666,7 @@
                               </p>
                               <p class="p">All kernels launched must be identical with respect to the compiled code. Note that any __device__, __constant__ or __managed__
                                  variables present in the module that owns the kernel launched on each device, are independently instantiated on every device.
-                                 It is the application's responsiblity to ensure these variables are initialized and used appropriately.
+                                 It is the application's responsibility to ensure these variables are initialized and used appropriately.
                               </p>
                               <p class="p">The size of the grids as specified in blocks, the size of the blocks themselves and the amount of shared memory used by each
                                  thread block must also match across all launched kernels.
--- a/nvidia-cuda/doc/html/cuda-driver-api/group__CUDA__PRIMARY__CTX.html
+++ b/nvidia-cuda/doc/html/cuda-driver-api/group__CUDA__PRIMARY__CTX.html
@@ -465,7 +465,7 @@
                            </div>
                            <div class="section">
                               <h6 class="description_header">Description</h6>
-                              <p>Sets the flags for the primary context on the device overwriting perviously set ones. If the primary context is already created
+                              <p>Sets the flags for the primary context on the device overwriting previously set ones. If the primary context is already created
                                  <a class="xref" href="group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e90d74711f16f63a410d8d94d02e1f5480" shape="rect">CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE</a> is returned.
                               </p>
                               <p class="p">The three LSBs of the <tt class="ph tt code">flags</tt> parameter can be used to control how the OS thread, which owns the CUDA context at the time of an API call, interacts with
--- a/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__EGL.html
+++ b/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__EGL.html
@@ -425,7 +425,7 @@
                               </h6>
                               <dl class="table-display-params">
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">conn</span></tt></dt>
-                                 <dd>- Conection to disconnect.</dd>
+                                 <dd>- Connection to disconnect.</dd>
                               </dl>
                            </div>
                            <div class="section">
@@ -525,7 +525,7 @@
                               </h6>
                               <dl class="table-display-params">
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">conn</span></tt></dt>
-                                 <dd>- Conection to disconnect.</dd>
+                                 <dd>- Connection to disconnect.</dd>
                               </dl>
                            </div>
                            <div class="section">
@@ -697,7 +697,7 @@
                                  operation which access the objects have completed before passing control to CUDA. This may be accomplished by issuing and
                                  waiting for glFinish command on all GLcontexts (for OpenGL and likewise for other APIs). The application will be also responsible
                                  for ensuring that any pending operation on the registered CUDA resource has completed prior to executing subsequent commands
-                                 in other APIs accesing the same memory objects. This can be accomplished by calling cuCtxSynchronize or cuEventSynchronize
+                                 in other APIs accessing the same memory objects. This can be accomplished by calling cuCtxSynchronize or cuEventSynchronize
                                  (preferably).
                               </p>
                               <p class="p">The surface's intended usage is specified using <tt class="ph tt code">flags</tt>, as follows:
--- a/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__EXECUTION.html
+++ b/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__EXECUTION.html
@@ -343,7 +343,7 @@
                                           <p class="p">Note that this function may also return error codes from previous, asynchronous launches. </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a function as the <tt class="ph tt code">func</tt> paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a function as the <tt class="ph tt code">func</tt> parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
@@ -463,7 +463,7 @@
                                           <p class="p">Note that this function may also return error codes from previous, asynchronous launches. </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a function as the <tt class="ph tt code">func</tt> paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a function as the <tt class="ph tt code">func</tt> parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
@@ -533,7 +533,7 @@
                                           <p class="p">Note that this function may also return error codes from previous, asynchronous launches. </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a function as the <tt class="ph tt code">func</tt> paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a function as the <tt class="ph tt code">func</tt> parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
@@ -648,9 +648,9 @@
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">func</span></tt></dt>
                                  <dd>- Device function symbol </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">gridDim</span></tt></dt>
-                                 <dd>- Grid dimentions </dd>
+                                 <dd>- Grid dimensions </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">blockDim</span></tt></dt>
-                                 <dd>- Block dimentions </dd>
+                                 <dd>- Block dimensions </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">args</span></tt></dt>
                                  <dd>- Arguments </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">sharedMem</span></tt></dt>
@@ -732,7 +732,7 @@
                                  All devices must have a non-zero value for the device attribute <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdd23f91b7405936dcbdb32cccf4598ea3" shape="rect">cudaDevAttrCooperativeMultiDeviceLaunch</a>.
                               </p>
                               <p class="p">The same kernel must be launched on all devices. Note that any __device__ or __constant__ variables are independently instantiated
-                                 on every device. It is the application's responsiblity to ensure these variables are initialized and used appropriately.
+                                 on every device. It is the application's responsibility to ensure these variables are initialized and used appropriately.
                               </p>
                               <p class="p">The size of the grids as specified in blocks, the size of the blocks themselves and the amount of shared memory used by each
                                  thread block must also match across all launched kernels.
@@ -823,9 +823,9 @@
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">func</span></tt></dt>
                                  <dd>- Device function symbol </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">gridDim</span></tt></dt>
-                                 <dd>- Grid dimentions </dd>
+                                 <dd>- Grid dimensions </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">blockDim</span></tt></dt>
-                                 <dd>- Block dimentions </dd>
+                                 <dd>- Block dimensions </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">args</span></tt></dt>
                                  <dd>- Arguments </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">sharedMem</span></tt></dt>
--- a/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__EXECUTION__DEPRECATED.html
+++ b/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__EXECUTION__DEPRECATED.html
@@ -367,7 +367,7 @@
                                           <p class="p">Note that this function may also return error codes from previous, asynchronous launches. </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> paramater was removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> parameter was removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
--- a/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__HIGHLEVEL.html
+++ b/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__HIGHLEVEL.html
@@ -371,7 +371,7 @@
                      <dd class="shortdesc"><span></span><span class="desc">Returns grid and block size that achieves maximum potential occupancy for a device function. </span></dd>
                      <dt><span class="template">template &lt; class T &gt;</span><span class="member_type"><span class="keyword keyword apiItemName">__host__</span>
                            <a href="group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" title="" shape="rect">cudaError_t</a>&nbsp;</span><span class="member_name"><a href="#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags</a> (  int*<span>&nbsp;</span><span class="keyword keyword apiItemName">minGridSize</span>, int*<span>&nbsp;</span><span class="keyword keyword apiItemName">blockSize</span>, T<span>&nbsp;</span><span class="keyword keyword apiItemName">func</span>, size_t<span>&nbsp;</span><span class="keyword keyword apiItemName">dynamicSMemSize</span> = <span class="ph ph apiData">0</span>, int <span>&nbsp;</span><span class="keyword keyword apiItemName">blockSizeLimit</span> = <span class="ph ph apiData">0</span>, unsigned int <span>&nbsp;</span><span class="keyword keyword apiItemName">flags</span> = <span class="ph ph apiData">0</span> ) </span></dt>
-                     <dd class="shortdesc"><span></span><span class="desc">Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags. </span></dd>
+                     <dd class="shortdesc"><span></span><span class="desc">Returns grid and block size that achieved maximum potential occupancy for a device function with the specified flags. </span></dd>
                      <dt><span class="template">template &lt; class T &gt;</span><span class="member_type"><span class="keyword keyword apiItemName">__host__</span>
                            <a href="group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" title="" shape="rect">cudaError_t</a>&nbsp;</span><span class="member_name"><a href="#group__CUDART__HIGHLEVEL_1g4941fcb557b10d07e920794421cf6059" shape="rect">cudaSetupArgument</a> (  T<span>&nbsp;</span><span class="keyword keyword apiItemName">arg</span>, size_t<span>&nbsp;</span><span class="keyword keyword apiItemName">offset</span> ) </span></dt>
                      <dd class="shortdesc"><span></span><span class="desc">[C++ API] Configure a device launch </span></dd>
@@ -1173,9 +1173,9 @@
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">func</span></tt></dt>
                                  <dd>- Device function symbol </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">gridDim</span></tt></dt>
-                                 <dd>- Grid dimentions </dd>
+                                 <dd>- Grid dimensions </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">blockDim</span></tt></dt>
-                                 <dd>- Block dimentions </dd>
+                                 <dd>- Block dimensions </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">args</span></tt></dt>
                                  <dd>- Arguments </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">sharedMem</span></tt></dt>
@@ -1238,9 +1238,9 @@
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">func</span></tt></dt>
                                  <dd>- Device function symbol </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">gridDim</span></tt></dt>
-                                 <dd>- Grid dimentions </dd>
+                                 <dd>- Grid dimensions </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">blockDim</span></tt></dt>
-                                 <dd>- Block dimentions </dd>
+                                 <dd>- Block dimensions </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">args</span></tt></dt>
                                  <dd>- Arguments </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">sharedMem</span></tt></dt>
@@ -1390,7 +1390,7 @@
                               </p>
                               <p class="p"><tt class="ph tt code">flags</tt> specifies the default stream association for this allocation. <tt class="ph tt code">flags</tt> must be one of <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">cudaMemAttachGlobal</a> or <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g4f9a428d18fdd89a99441d0dd27131c0" shape="rect">cudaMemAttachHost</a>. The default value for <tt class="ph tt code">flags</tt> is <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">cudaMemAttachGlobal</a>. If <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">cudaMemAttachGlobal</a> is specified, then this memory is accessible from any stream on any device. If <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g4f9a428d18fdd89a99441d0dd27131c0" shape="rect">cudaMemAttachHost</a> is specified, then the allocation should not be accessed from devices that have a zero value for the device attribute <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">cudaDevAttrConcurrentManagedAccess</a>; an explicit call to <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g496353d630c29c44a2e33f531a3944d1" title="Attach memory to a stream asynchronously." shape="rect">cudaStreamAttachMemAsync</a> will be required to enable access on such devices.
                               </p>
-                              <p class="p">If the association is later changed via <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g496353d630c29c44a2e33f531a3944d1" title="Attach memory to a stream asynchronously." shape="rect">cudaStreamAttachMemAsync</a> to a single stream, the default association, as specifed during <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" title="Allocates memory that will be automatically managed by the Unified Memory system." shape="rect">cudaMallocManaged</a>, is restored when that stream is destroyed. For __managed__ variables, the default association is always <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">cudaMemAttachGlobal</a>. Note that destroying a stream is an asynchronous operation, and as a result, the change to default association won't happen
+                              <p class="p">If the association is later changed via <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g496353d630c29c44a2e33f531a3944d1" title="Attach memory to a stream asynchronously." shape="rect">cudaStreamAttachMemAsync</a> to a single stream, the default association, as specified during <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" title="Allocates memory that will be automatically managed by the Unified Memory system." shape="rect">cudaMallocManaged</a>, is restored when that stream is destroyed. For __managed__ variables, the default association is always <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">cudaMemAttachGlobal</a>. Note that destroying a stream is an asynchronous operation, and as a result, the change to default association won't happen
                                  until all work in the stream has completed.
                               </p>
                               <p class="p">Memory allocated with <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" title="Allocates memory that will be automatically managed by the Unified Memory system." shape="rect">cudaMallocManaged</a> should be released with <a class="xref" href="group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" title="Frees memory on the device." shape="rect">cudaFree</a>.
@@ -1486,7 +1486,7 @@
                                           </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
@@ -1546,7 +1546,7 @@
                                           </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
@@ -1601,7 +1601,7 @@
                                           </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
@@ -1661,7 +1661,7 @@
                                           </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
@@ -1687,7 +1687,7 @@
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">numBlocks</span></tt></dt>
                                  <dd>- Returned occupancy </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">func</span></tt></dt>
-                                 <dd>- Kernel function for which occupancy is calulated </dd>
+                                 <dd>- Kernel function for which occupancy is calculated </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">blockSize</span></tt></dt>
                                  <dd>- Block size the kernel is intended to be launched with </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">dynamicSMemSize</span></tt></dt>
@@ -1713,7 +1713,7 @@
                               <p class="p apiDesc_subtitle"><strong class="ph b">See also:</strong></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g603b86b20b37823253ff89fe8688ba83" title="Returns occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags</a></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSize</a></p>
-                              <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags</a></p>
+                              <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achieved maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags</a></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g77b3bfb154b86e215a5bc01509ce8ea6" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMem</a></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g76975517a048cc199bc9e3ea6396ef26" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags</a></p>
                               <p class="p"></p>
@@ -1733,7 +1733,7 @@
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">numBlocks</span></tt></dt>
                                  <dd>- Returned occupancy </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">func</span></tt></dt>
-                                 <dd>- Kernel function for which occupancy is calulated </dd>
+                                 <dd>- Kernel function for which occupancy is calculated </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">blockSize</span></tt></dt>
                                  <dd>- Block size the kernel is intended to be launched with </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">dynamicSMemSize</span></tt></dt>
@@ -1781,7 +1781,7 @@
                               <p class="p apiDesc_subtitle"><strong class="ph b">See also:</strong></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g5a5d67a3c907371559ba692195e8a38c" title="Returns occupancy for a device function." shape="rect">cudaOccupancyMaxActiveBlocksPerMultiprocessor</a></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSize</a></p>
-                              <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags</a></p>
+                              <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achieved maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags</a></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g77b3bfb154b86e215a5bc01509ce8ea6" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMem</a></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g76975517a048cc199bc9e3ea6396ef26" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags</a></p>
                               <p class="p"></p>
@@ -1833,7 +1833,7 @@
                               </p>
                               <p class="p"></p>
                               <p class="p apiDesc_subtitle"><strong class="ph b">See also:</strong></p>
-                              <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags</a></p>
+                              <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achieved maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags</a></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g5a5d67a3c907371559ba692195e8a38c" title="Returns occupancy for a device function." shape="rect">cudaOccupancyMaxActiveBlocksPerMultiprocessor</a></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g603b86b20b37823253ff89fe8688ba83" title="Returns occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags</a></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g77b3bfb154b86e215a5bc01509ce8ea6" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMem</a></p>
@@ -1889,7 +1889,7 @@
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g5a5d67a3c907371559ba692195e8a38c" title="Returns occupancy for a device function." shape="rect">cudaOccupancyMaxActiveBlocksPerMultiprocessor</a></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g603b86b20b37823253ff89fe8688ba83" title="Returns occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags</a></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSize</a></p>
-                              <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags</a></p>
+                              <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achieved maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags</a></p>
                               <p class="p"></p>
                            </div>
                         </dd>
@@ -1963,7 +1963,7 @@
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g5a5d67a3c907371559ba692195e8a38c" title="Returns occupancy for a device function." shape="rect">cudaOccupancyMaxActiveBlocksPerMultiprocessor</a></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g603b86b20b37823253ff89fe8688ba83" title="Returns occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags</a></p>
                               <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSize</a></p>
-                              <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags</a></p>
+                              <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achieved maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags</a></p>
                               <p class="p"></p>
                            </div>
                         </dd>
@@ -1971,7 +1971,7 @@
                               <!-- --></a><p class="template">template &lt; class T &gt;</p><span><span class="keyword keyword apiItemName">__host__</span>
                               <a href="group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" title="" shape="rect">cudaError_t</a> cudaOccupancyMaxPotentialBlockSizeWithFlags (  int*<span>&nbsp;</span><span class="keyword keyword apiItemName">minGridSize</span>, int*<span>&nbsp;</span><span class="keyword keyword apiItemName">blockSize</span>, T<span>&nbsp;</span><span class="keyword keyword apiItemName">func</span>, size_t<span>&nbsp;</span><span class="keyword keyword apiItemName">dynamicSMemSize</span> = <span class="ph ph apiData">0</span>, int <span>&nbsp;</span><span class="keyword keyword apiItemName">blockSizeLimit</span> = <span class="ph ph apiData">0</span>, unsigned int <span>&nbsp;</span><span class="keyword keyword apiItemName">flags</span> = <span class="ph ph apiData">0</span> )  [inline] </span></dt>
                         <dd class="description">
-                           <div class="section">Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags. </div>
+                           <div class="section">Returns grid and block size that achieved maximum potential occupancy for a device function with the specified flags. </div>
                            <div class="section">
                               <h6 class="parameter_header">
                                  Parameters
--- a/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__MEMORY.html
+++ b/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__MEMORY.html
@@ -725,7 +725,7 @@
                                           <p class="p">Note that this function may also return error codes from previous, asynchronous launches. </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
@@ -770,7 +770,7 @@
                                           <p class="p">Note that this function may also return error codes from previous, asynchronous launches. </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
@@ -1475,7 +1475,7 @@
                               </p>
                               <p class="p"><tt class="ph tt code">flags</tt> specifies the default stream association for this allocation. <tt class="ph tt code">flags</tt> must be one of <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">cudaMemAttachGlobal</a> or <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g4f9a428d18fdd89a99441d0dd27131c0" shape="rect">cudaMemAttachHost</a>. The default value for <tt class="ph tt code">flags</tt> is <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">cudaMemAttachGlobal</a>. If <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">cudaMemAttachGlobal</a> is specified, then this memory is accessible from any stream on any device. If <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g4f9a428d18fdd89a99441d0dd27131c0" shape="rect">cudaMemAttachHost</a> is specified, then the allocation should not be accessed from devices that have a zero value for the device attribute <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">cudaDevAttrConcurrentManagedAccess</a>; an explicit call to <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g496353d630c29c44a2e33f531a3944d1" title="Attach memory to a stream asynchronously." shape="rect">cudaStreamAttachMemAsync</a> will be required to enable access on such devices.
                               </p>
-                              <p class="p">If the association is later changed via <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g496353d630c29c44a2e33f531a3944d1" title="Attach memory to a stream asynchronously." shape="rect">cudaStreamAttachMemAsync</a> to a single stream, the default association, as specifed during <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" title="Allocates memory that will be automatically managed by the Unified Memory system." shape="rect">cudaMallocManaged</a>, is restored when that stream is destroyed. For __managed__ variables, the default association is always <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">cudaMemAttachGlobal</a>. Note that destroying a stream is an asynchronous operation, and as a result, the change to default association won't happen
+                              <p class="p">If the association is later changed via <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g496353d630c29c44a2e33f531a3944d1" title="Attach memory to a stream asynchronously." shape="rect">cudaStreamAttachMemAsync</a> to a single stream, the default association, as specified during <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" title="Allocates memory that will be automatically managed by the Unified Memory system." shape="rect">cudaMallocManaged</a>, is restored when that stream is destroyed. For __managed__ variables, the default association is always <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">cudaMemAttachGlobal</a>. Note that destroying a stream is an asynchronous operation, and as a result, the change to default association won't happen
                                  until all work in the stream has completed.
                               </p>
                               <p class="p">Memory allocated with <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" title="Allocates memory that will be automatically managed by the Unified Memory system." shape="rect">cudaMallocManaged</a> should be released with <a class="xref" href="group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" title="Frees memory on the device." shape="rect">cudaFree</a>.
@@ -2682,7 +2682,7 @@
         enum <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect">cudaMemcpyKind</a>   
                   <a class="xref" href="structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_10caa37ba0134b351170924565d07be20" shape="rect">kind</a>;
       };</pre></p>
-                              <p class="p"><a class="xref" href="group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" title="Copies data between 3D objects." shape="rect">cudaMemcpy3D()</a> copies data betwen two 3D objects. The source and destination objects may be in either host memory, device memory, or a CUDA
+                              <p class="p"><a class="xref" href="group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" title="Copies data between 3D objects." shape="rect">cudaMemcpy3D()</a> copies data between two 3D objects. The source and destination objects may be in either host memory, device memory, or a CUDA
                                  array. The source, destination, extent, and kind of copy performed is specified by the <a class="xref" href="structcudaMemcpy3DParms.html#structcudaMemcpy3DParms" shape="rect">cudaMemcpy3DParms</a> struct which should be initialized to zero before use: <pre xml:space="preserve"><a class="xref" href="structcudaMemcpy3DParms.html#structcudaMemcpy3DParms" shape="rect">cudaMemcpy3DParms</a> myParms = {0};</pre></p>
                               <p class="p">The struct passed to <a class="xref" href="group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" title="Copies data between 3D objects." shape="rect">cudaMemcpy3D()</a> must specify one of <tt class="ph tt code">srcArray</tt> or <tt class="ph tt code">srcPtr</tt> and one of <tt class="ph tt code">dstArray</tt> or <tt class="ph tt code">dstPtr</tt>. Passing more than one non-zero source or destination will cause <a class="xref" href="group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" title="Copies data between 3D objects." shape="rect">cudaMemcpy3D()</a> to return an error.
                               </p>
@@ -2785,7 +2785,7 @@
         enum <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect">cudaMemcpyKind</a>   
                   <a class="xref" href="structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_10caa37ba0134b351170924565d07be20" shape="rect">kind</a>;
       };</pre></p>
-                              <p class="p"><a class="xref" href="group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" title="Copies data between 3D objects." shape="rect">cudaMemcpy3DAsync()</a> copies data betwen two 3D objects. The source and destination objects may be in either host memory, device memory, or a CUDA
+                              <p class="p"><a class="xref" href="group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" title="Copies data between 3D objects." shape="rect">cudaMemcpy3DAsync()</a> copies data between two 3D objects. The source and destination objects may be in either host memory, device memory, or a CUDA
                                  array. The source, destination, extent, and kind of copy performed is specified by the <a class="xref" href="structcudaMemcpy3DParms.html#structcudaMemcpy3DParms" shape="rect">cudaMemcpy3DParms</a> struct which should be initialized to zero before use: <pre xml:space="preserve"><a class="xref" href="structcudaMemcpy3DParms.html#structcudaMemcpy3DParms" shape="rect">cudaMemcpy3DParms</a> myParms = {0};</pre></p>
                               <p class="p">The struct passed to <a class="xref" href="group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" title="Copies data between 3D objects." shape="rect">cudaMemcpy3DAsync()</a> must specify one of <tt class="ph tt code">srcArray</tt> or <tt class="ph tt code">srcPtr</tt> and one of <tt class="ph tt code">dstArray</tt> or <tt class="ph tt code">dstPtr</tt>. Passing more than one non-zero source or destination will cause <a class="xref" href="group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" title="Copies data between 3D objects." shape="rect">cudaMemcpy3DAsync()</a> to return an error.
                               </p>
@@ -3203,7 +3203,7 @@
                                           </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
@@ -3267,7 +3267,7 @@
                                           </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
@@ -3549,7 +3549,7 @@
                                           </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
@@ -3613,7 +3613,7 @@
                                           </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
--- a/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__OCCUPANCY.html
+++ b/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__OCCUPANCY.html
@@ -264,7 +264,7 @@
                      <p>This section describes the occupancy calculation functions of the CUDA runtime application programming interface.</p>
                      <p class="p">Besides the occupancy calculator functions (<a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g5a5d67a3c907371559ba692195e8a38c" title="Returns occupancy for a device function." shape="rect">cudaOccupancyMaxActiveBlocksPerMultiprocessor</a> and <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g603b86b20b37823253ff89fe8688ba83" title="Returns occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags</a>), there are also C++ only occupancy-based launch configuration functions documented in <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL" title="C++-style interface built on top of CUDA runtime API." shape="rect">C++ API Routines</a> module.
                      </p>
-                     <p class="p">See <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSize ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSize ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g77b3bfb154b86e215a5bc01509ce8ea6" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMem ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g76975517a048cc199bc9e3ea6396ef26" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMem ( C++ API)</a></p>
+                     <p class="p">See <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSize ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achieved maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSize ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g77b3bfb154b86e215a5bc01509ce8ea6" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMem ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g76975517a048cc199bc9e3ea6396ef26" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMem ( C++ API)</a></p>
                   </div>
                   <h3 class="fake_sectiontitle member_header">Functions</h3>
                   <dl class="members">
@@ -320,7 +320,7 @@
                               </p>
                               <p class="p"></p>
                               <p class="p apiDesc_subtitle"><strong class="ph b">See also:</strong></p>
-                              <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g603b86b20b37823253ff89fe8688ba83" title="Returns occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSize ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g77b3bfb154b86e215a5bc01509ce8ea6" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMem ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g76975517a048cc199bc9e3ea6396ef26" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags ( C++ API)</a>, <a class="xref" href="../cuda-driver-api/group__CUDA__OCCUPANCY.html#group__CUDA__OCCUPANCY_1gcc6e1094d05cba2cee17fe33ddd04a98" target="_blank" shape="rect">cuOccupancyMaxActiveBlocksPerMultiprocessor</a></p>
+                              <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g603b86b20b37823253ff89fe8688ba83" title="Returns occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSize ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achieved maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g77b3bfb154b86e215a5bc01509ce8ea6" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMem ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g76975517a048cc199bc9e3ea6396ef26" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags ( C++ API)</a>, <a class="xref" href="../cuda-driver-api/group__CUDA__OCCUPANCY.html#group__CUDA__OCCUPANCY_1gcc6e1094d05cba2cee17fe33ddd04a98" target="_blank" shape="rect">cuOccupancyMaxActiveBlocksPerMultiprocessor</a></p>
                               <p class="p"></p>
                            </div>
                         </dd>
@@ -384,7 +384,7 @@
                               </p>
                               <p class="p"></p>
                               <p class="p apiDesc_subtitle"><strong class="ph b">See also:</strong></p>
-                              <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g5a5d67a3c907371559ba692195e8a38c" title="Returns occupancy for a device function." shape="rect">cudaOccupancyMaxActiveBlocksPerMultiprocessor</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSize ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g77b3bfb154b86e215a5bc01509ce8ea6" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMem ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g76975517a048cc199bc9e3ea6396ef26" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags ( C++ API)</a>, <a class="xref" href="../cuda-driver-api/group__CUDA__OCCUPANCY.html#group__CUDA__OCCUPANCY_1g8f1da4d4983e5c3025447665423ae2c2" target="_blank" shape="rect">cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags</a></p>
+                              <p class="p see_subsection"><a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g5a5d67a3c907371559ba692195e8a38c" title="Returns occupancy for a device function." shape="rect">cudaOccupancyMaxActiveBlocksPerMultiprocessor</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSize ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" title="Returns grid and block size that achieved maximum potential occupancy for a device function with the specified flags." shape="rect">cudaOccupancyMaxPotentialBlockSizeWithFlags ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g77b3bfb154b86e215a5bc01509ce8ea6" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMem ( C++ API)</a>, <a class="xref" href="group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g76975517a048cc199bc9e3ea6396ef26" title="Returns grid and block size that achieves maximum potential occupancy for a device function." shape="rect">cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags ( C++ API)</a>, <a class="xref" href="../cuda-driver-api/group__CUDA__OCCUPANCY.html#group__CUDA__OCCUPANCY_1g8f1da4d4983e5c3025447665423ae2c2" target="_blank" shape="rect">cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags</a></p>
                               <p class="p"></p>
                            </div>
                         </dd>
--- a/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__SURFACE.html
+++ b/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__SURFACE.html
@@ -349,7 +349,7 @@
                                           <p class="p">Note that this function may also return error codes from previous, asynchronous launches. </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> paramater was removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> parameter was removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
--- a/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__TEXTURE.html
+++ b/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__TEXTURE.html
@@ -631,7 +631,7 @@
                                           <p class="p">Note that this function may also return error codes from previous, asynchronous launches. </p>
                                        </li>
                                        <li class="li">
-                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> paramater was removed in CUDA 5.0.
+                                          <p class="p">Use of a string naming a variable as the <tt class="ph tt code">symbol</tt> parameter was removed in CUDA 5.0.
                                           </p>
                                        </li>
                                     </ul>
--- a/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__TYPES.html
+++ b/nvidia-cuda/doc/html/cuda-runtime-api/group__CUDART__TYPES.html
@@ -1965,7 +1965,7 @@
                               </h6>
                               <dl class="enumerator">
                                  <dt><span class="enum-member-name-def">cudaMemRangeAttributeReadMostly = <span class="ph ph apiData">1</span></span></dt>
-                                 <dd>Whether the range will mostly be read and only occassionally be written to </dd>
+                                 <dd>Whether the range will mostly be read and only occasionally be written to </dd>
                                  <dt><span class="enum-member-name-def">cudaMemRangeAttributePreferredLocation = <span class="ph ph apiData">2</span></span></dt>
                                  <dd>The preferred location of the range </dd>
                                  <dt><span class="enum-member-name-def">cudaMemRangeAttributeAccessedBy = <span class="ph ph apiData">3</span></span></dt>
@@ -2014,7 +2014,7 @@
                               </h6>
                               <dl class="enumerator">
                                  <dt><span class="enum-member-name-def">cudaMemAdviseSetReadMostly = <span class="ph ph apiData">1</span></span></dt>
-                                 <dd>Data will mostly be read and only occassionally be written to </dd>
+                                 <dd>Data will mostly be read and only occasionally be written to </dd>
                                  <dt><span class="enum-member-name-def">cudaMemAdviseUnsetReadMostly = <span class="ph ph apiData">2</span></span></dt>
                                  <dd>Undo the effect of <a class="xref" href="group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857441d911811beda174627f403142d5ff0" shape="rect">cudaMemAdviseSetReadMostly</a></dd>
                                  <dt><span class="enum-member-name-def">cudaMemAdviseSetPreferredLocation = <span class="ph ph apiData">3</span></span></dt>
--- a/nvidia-cuda/doc/html/cuda-runtime-api/structcudaLaunchParams.html
+++ b/nvidia-cuda/doc/html/cuda-runtime-api/structcudaLaunchParams.html
@@ -303,7 +303,7 @@
                               <!-- --></a><span>dim3  <a href="structcudaLaunchParams.html#structcudaLaunchParams" title="" shape="rect">cudaLaunchParams</a>::<a href="structcudaLaunchParams.html#structcudaLaunchParams_1dd319c6a16b02bdcce0c08fb3e03b87f" shape="rect">blockDim</a> [inherited] </span></dt>
                         <dd class="description">
                            <div class="section">
-                              <p> Block dimentions </p>
+                              <p> Block dimensions </p>
                            </div>
                         </dd>
                         <dt class="description"><a name="structcudaLaunchParams_1b83c5ba1757e15e87386300690c9b081" id="structcudaLaunchParams_1b83c5ba1757e15e87386300690c9b081" shape="rect">
@@ -320,7 +320,7 @@
                               <!-- --></a><span>dim3  <a href="structcudaLaunchParams.html#structcudaLaunchParams" title="" shape="rect">cudaLaunchParams</a>::<a href="structcudaLaunchParams.html#structcudaLaunchParams_1ad6b5e617a8c137476babb2ca1b94570" shape="rect">gridDim</a> [inherited] </span></dt>
                         <dd class="description">
                            <div class="section">
-                              <p> Grid dimentions </p>
+                              <p> Grid dimensions </p>
                            </div>
                         </dd>
                         <dt class="description"><a name="structcudaLaunchParams_186f6dff594ff6d496509a9f3c6607f17" id="structcudaLaunchParams_186f6dff594ff6d496509a9f3c6607f17" shape="rect">
--- a/nvidia-cuda/doc/html/cupti/group__CUPTI__CALLBACK__API.html
+++ b/nvidia-cuda/doc/html/cupti/group__CUPTI__CALLBACK__API.html
@@ -917,7 +917,7 @@
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">callback</span></tt></dt>
                                  <dd>The callback function </dd>
                                  <dt><tt class="code"><span class="keyword keyword apiItemName">userdata</span></tt></dt>
-                                 <dd>A pointer to user data. This data will be passed to the callback function via the <tt class="ph tt code">userdata</tt> paramater.
+                                 <dd>A pointer to user data. This data will be passed to the callback function via the <tt class="ph tt code">userdata</tt> parameter.
                                  </dd>
                               </dl>
                            </div>
--- a/nvidia-cuda/doc/html/profiler-users-guide/index.html
+++ b/nvidia-cuda/doc/html/profiler-users-guide/index.html
@@ -4051,7 +4051,7 @@ Critical path(%)  Critical path  Waiting
                         <!-- --></a><h3 class="title topictitle2"><a href="#openacc" name="openacc" shape="rect">3.6.&nbsp;OpenACC</a></h3>
                      <div class="body conbody">
                         <p class="p">On 64bit Linux platforms, <samp class="ph codeph"><span class="keyword">nvprof</span></samp> supports recording OpenACC activities
-                           using the CUPTI Activity API.  This allows to investigate the
+                           using the CUPTI Activity API.  This allows one to investigate the
                            performance on the level of OpenACC constructs in addition to the
                            underlying, compiler-generated CUDA API calls.  
                         </p>
@@ -5064,7 +5064,7 @@ $ mpirun -np 2 -host c0-0,c0-1 <span cla
                   <div class="body conbody">
                      <p class="p">The dependency analysis feature enables optimization of the program
                         runtime and concurrency of applications utilizing multiple CPU threads and
-                        CUDA streams. It allows to compute the critical path of a specific
+                        CUDA streams. It allows one to compute the critical path of a specific
                         execution, detect waiting time and inspect dependencies between functions
                         executing in different threads or streams.
                      </p>
--- a/nvidia-cuda/doc/man/man3/CUDART_D3D9.3
+++ b/nvidia-cuda/doc/man/man3/CUDART_D3D9.3
@@ -151,7 +151,7 @@ If \fCdevice\fP has already been initial
 .PP
 Successfully initializing CUDA interoperability with \fCpD3D9Device\fP will increase the internal reference count on \fCpD3D9Device\fP. This reference count will be decremented when \fCdevice\fP is reset using \fBcudaDeviceReset()\fP.
 .PP
-Note that this function is never required for correct functionality. Use of this function will result in accelerated interoperability only when the operating system is Windows Vista or Windows 7, and the device \fCpD3DDdevice\fP is not an IDirect3DDevice9Ex. In all other cirumstances, this function is not necessary.
+Note that this function is never required for correct functionality. Use of this function will result in accelerated interoperability only when the operating system is Windows Vista or Windows 7, and the device \fCpD3DDdevice\fP is not an IDirect3DDevice9Ex. In all other circumstances, this function is not necessary.
 .PP
 \fBParameters:\fP
 .RS 4
--- a/nvidia-cuda/doc/man/man3/CUDART_EGL.3
+++ b/nvidia-cuda/doc/man/man3/CUDART_EGL.3
@@ -142,7 +142,7 @@ Disconnect CUDA as a consumer to EGLStre
 .PP
 \fBParameters:\fP
 .RS 4
-\fIconn\fP - Conection to disconnect.
+\fIconn\fP - Connection to disconnect.
 .RE
 .PP
 \fBReturns:\fP
@@ -214,7 +214,7 @@ Disconnect CUDA as a producer to EGLStre
 .PP
 \fBParameters:\fP
 .RS 4
-\fIconn\fP - Conection to disconnect.
+\fIconn\fP - Connection to disconnect.
 .RE
 .PP
 \fBReturns:\fP
@@ -328,7 +328,7 @@ The EGLSyncKHR is an opaque handle to an
 .PP
 Registers the EGLImageKHR specified by \fCimage\fP for access by CUDA. A handle to the registered object is returned as \fCpCudaResource\fP. Additional Mapping/Unmapping is not required for the registered resource and \fBcudaGraphicsResourceGetMappedEglFrame\fP can be directly called on the \fCpCudaResource\fP.
 .PP
-The application will be responsible for synchronizing access to shared objects. The application must ensure that any pending operation which access the objects have completed before passing control to CUDA. This may be accomplished by issuing and waiting for glFinish command on all GLcontexts (for OpenGL and likewise for other APIs). The application will be also responsible for ensuring that any pending operation on the registered CUDA resource has completed prior to executing subsequent commands in other APIs accesing the same memory objects. This can be accomplished by calling cuCtxSynchronize or cuEventSynchronize (preferably).
+The application will be responsible for synchronizing access to shared objects. The application must ensure that any pending operation which access the objects have completed before passing control to CUDA. This may be accomplished by issuing and waiting for glFinish command on all GLcontexts (for OpenGL and likewise for other APIs). The application will be also responsible for ensuring that any pending operation on the registered CUDA resource has completed prior to executing subsequent commands in other APIs accessing the same memory objects. This can be accomplished by calling cuCtxSynchronize or cuEventSynchronize (preferably).
 .PP
 The surface's intended usage is specified using \fCflags\fP, as follows:
 .PP
--- a/nvidia-cuda/doc/man/man3/CUDART_TYPES.3
+++ b/nvidia-cuda/doc/man/man3/CUDART_TYPES.3
@@ -1621,7 +1621,7 @@ CUDA Memory Advise values
 .in +1c
 .TP
 \fB\fIcudaMemAdviseSetReadMostly \fP\fP
-Data will mostly be read and only occassionally be written to 
+Data will mostly be read and only occasionally be written to 
 .TP
 \fB\fIcudaMemAdviseUnsetReadMostly \fP\fP
 Undo the effect of \fBcudaMemAdviseSetReadMostly\fP 
@@ -1657,7 +1657,7 @@ CUDA range attributes
 .in +1c
 .TP
 \fB\fIcudaMemRangeAttributeReadMostly \fP\fP
-Whether the range will mostly be read and only occassionally be written to 
+Whether the range will mostly be read and only occasionally be written to 
 .TP
 \fB\fIcudaMemRangeAttributePreferredLocation \fP\fP
 The preferred location of the range 
--- a/nvidia-cuda/doc/man/man3/CUDA_DEVICE_DEPRECATED.3
+++ b/nvidia-cuda/doc/man/man3/CUDA_DEVICE_DEPRECATED.3
@@ -28,7 +28,7 @@ This section describes the device manage
 .RS 4
 .RE
 .PP
-This function was deprecated as of CUDA 5.0 and its functionality superceded by \fBcuDeviceGetAttribute()\fP.
+This function was deprecated as of CUDA 5.0 and its functionality superseded by \fBcuDeviceGetAttribute()\fP.
 .PP
 Returns in \fC*major\fP and \fC*minor\fP the major and minor revision numbers that define the compute capability of the device \fCdev\fP.
 .PP
--- a/nvidia-cuda/doc/man/man3/CUDA_EGL.3
+++ b/nvidia-cuda/doc/man/man3/CUDA_EGL.3
@@ -146,7 +146,7 @@ The EGLStreamKHR is an EGL object that t
 .PP
 \fBParameters:\fP
 .RS 4
-\fIconn\fP - Conection to disconnect.
+\fIconn\fP - Connection to disconnect.
 .RE
 .PP
 \fBReturns:\fP
@@ -222,7 +222,7 @@ The EGLStreamKHR is an EGL object that t
 .PP
 \fBParameters:\fP
 .RS 4
-\fIconn\fP - Conection to disconnect.
+\fIconn\fP - Connection to disconnect.
 .RE
 .PP
 \fBReturns:\fP
@@ -345,7 +345,7 @@ The EGLSyncKHR is an opaque handle to an
 .PP
 Registers the EGLImageKHR specified by \fCimage\fP for access by CUDA. A handle to the registered object is returned as \fCpCudaResource\fP. Additional Mapping/Unmapping is not required for the registered resource and \fBcuGraphicsResourceGetMappedEglFrame\fP can be directly called on the \fCpCudaResource\fP.
 .PP
-The application will be responsible for synchronizing access to shared objects. The application must ensure that any pending operation which access the objects have completed before passing control to CUDA. This may be accomplished by issuing and waiting for glFinish command on all GLcontexts (for OpenGL and likewise for other APIs). The application will be also responsible for ensuring that any pending operation on the registered CUDA resource has completed prior to executing subsequent commands in other APIs accesing the same memory objects. This can be accomplished by calling cuCtxSynchronize or cuEventSynchronize (preferably).
+The application will be responsible for synchronizing access to shared objects. The application must ensure that any pending operation which access the objects have completed before passing control to CUDA. This may be accomplished by issuing and waiting for glFinish command on all GLcontexts (for OpenGL and likewise for other APIs). The application will be also responsible for ensuring that any pending operation on the registered CUDA resource has completed prior to executing subsequent commands in other APIs accessing the same memory objects. This can be accomplished by calling cuCtxSynchronize or cuEventSynchronize (preferably).
 .PP
 The surface's intended usage is specified using \fCflags\fP, as follows:
 .PP
--- a/nvidia-cuda/doc/man/man3/cudaLaunchParams.3
+++ b/nvidia-cuda/doc/man/man3/cudaLaunchParams.3
@@ -38,13 +38,13 @@ CUDA launch parameters
 Arguments 
 .SS "dim3 \fBcudaLaunchParams::blockDim\fP"
 .PP
-Block dimentions 
+Block dimensions 
 .SS "void* \fBcudaLaunchParams::func\fP"
 .PP
 Device function symbol 
 .SS "dim3 \fBcudaLaunchParams::gridDim\fP"
 .PP
-Grid dimentions 
+Grid dimensions 
 .SS "size_t \fBcudaLaunchParams::sharedMem\fP"
 .PP
 Shared memory 
--- a/nvidia-cuda/doc/man/man3/nvmlDeviceEnumvs.3
+++ b/nvidia-cuda/doc/man/man3/nvmlDeviceEnumvs.3
@@ -221,7 +221,7 @@ Feature enabled.
 .PP
 GPU Operation Mode
 .PP
-GOM allows to reduce power usage and optimize GPU throughput by disabling GPU features.
+GOM allows one to reduce power usage and optimize GPU throughput by disabling GPU features.
 .PP
 Each GOM is designed to meet specific user needs. 
 .PP
@@ -460,7 +460,7 @@ Insufficient memory.
 No data. 
 .TP
 \fB\fINVML_ERROR_VGPU_ECC_NOT_SUPPORTED \fP\fP
-The requested vgpu operation is not available on target device, becasue ECC is enabled. 
+The requested vgpu operation is not available on target device, because ECC is enabled. 
 .TP
 \fB\fINVML_ERROR_UNKNOWN \fP\fP
 An internal driver error occurred. 
--- a/nvidia-cuda/doc/man/man3/nvmlDeviceQueries.3
+++ b/nvidia-cuda/doc/man/man3/nvmlDeviceQueries.3
@@ -1238,7 +1238,7 @@ Retrieves information about active encod
 .PP
 An array of active encoder sessions is returned in the caller-supplied buffer pointed at by \fIsessionInfos\fP. The array elememt count is passed in \fIsessionCount\fP, and \fIsessionCount\fP is used to return the number of sessions written to the buffer.
 .PP
-If the supplied buffer is not large enough to accomodate the active session array, the function returns NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlEncoderSessionInfo_t array required in \fIsessionCount\fP. To query the number of active encoder sessions, call this function with *sessionCount = 0. The code will return NVML_SUCCESS with number of active encoder sessions updated in *sessionCount.
+If the supplied buffer is not large enough to accommodate the active session array, the function returns NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlEncoderSessionInfo_t array required in \fIsessionCount\fP. To query the number of active encoder sessions, call this function with *sessionCount = 0. The code will return NVML_SUCCESS with number of active encoder sessions updated in *sessionCount.
 .PP
 For Maxwell (TM) or newer fully supported devices.
 .PP
--- a/nvidia-cuda/doc/man/man3/nvmlVgpu.3
+++ b/nvidia-cuda/doc/man/man3/nvmlVgpu.3
@@ -99,7 +99,7 @@ Retrieve the active vGPU instances on a
 .PP
 An array of active vGPU instances is returned in the caller-supplied buffer pointed at by \fIvgpuInstances\fP. The array elememt count is passed in \fIvgpuCount\fP, and \fIvgpuCount\fP is used to return the number of vGPU instances written to the buffer.
 .PP
-If the supplied buffer is not large enough to accomodate the vGPU instance array, the function returns NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlVgpuInstance_t array required in \fIvgpuCount\fP. To query the number of active vGPU instances, call this function with *vgpuCount = 0. The code will return NVML_ERROR_INSUFFICIENT_SIZE, or NVML_SUCCESS if no vGPU Types are supported.
+If the supplied buffer is not large enough to accommodate the vGPU instance array, the function returns NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlVgpuInstance_t array required in \fIvgpuCount\fP. To query the number of active vGPU instances, call this function with *vgpuCount = 0. The code will return NVML_ERROR_INSUFFICIENT_SIZE, or NVML_SUCCESS if no vGPU Types are supported.
 .PP
 For Kepler (TM) or newer fully supported devices.
 .PP
@@ -138,7 +138,7 @@ An array of creatable vGPU types for the
 .PP
 The creatable vGPU types for a device may differ over time, as there may be restrictions on what type of vGPU types can concurrently run on a device. For example, if only one vGPU type is allowed at a time on a device, then the creatable list will be restricted to whatever vGPU type is already running on the device.
 .PP
-If the supplied buffer is not large enough to accomodate the vGPU type array, the function returns NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlVgpuTypeId_t array required in \fIvgpuCount\fP. To query the number of vGPU types createable for the GPU, call this function with *vgpuCount = 0. The code will return NVML_ERROR_INSUFFICIENT_SIZE, or NVML_SUCCESS if no vGPU types are creatable.
+If the supplied buffer is not large enough to accommodate the vGPU type array, the function returns NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlVgpuTypeId_t array required in \fIvgpuCount\fP. To query the number of vGPU types createable for the GPU, call this function with *vgpuCount = 0. The code will return NVML_ERROR_INSUFFICIENT_SIZE, or NVML_SUCCESS if no vGPU types are creatable.
 .PP
 \fBParameters:\fP
 .RS 4
@@ -241,7 +241,7 @@ Retrieve the supported vGPU types on a p
 .PP
 An array of supported vGPU types for the physical GPU indicated by \fIdevice\fP is returned in the caller-supplied buffer pointed at by \fIvgpuTypeIds\fP. The element count of nvmlVgpuTypeId_t array is passed in \fIvgpuCount\fP, and \fIvgpuCount\fP is used to return the number of vGPU types written to the buffer.
 .PP
-If the supplied buffer is not large enough to accomodate the vGPU type array, the function returns NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlVgpuTypeId_t array required in \fIvgpuCount\fP. To query the number of vGPU types supported for the GPU, call this function with *vgpuCount = 0. The code will return NVML_ERROR_INSUFFICIENT_SIZE, or NVML_SUCCESS if no vGPU types are supported.
+If the supplied buffer is not large enough to accommodate the vGPU type array, the function returns NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlVgpuTypeId_t array required in \fIvgpuCount\fP. To query the number of vGPU types supported for the GPU, call this function with *vgpuCount = 0. The code will return NVML_ERROR_INSUFFICIENT_SIZE, or NVML_SUCCESS if no vGPU types are supported.
 .PP
 \fBParameters:\fP
 .RS 4
@@ -382,7 +382,7 @@ For Maxwell (TM) or newer fully supporte
 \fBReturns:\fP
 .RS 4
 .IP "\(bu" 2
-\fBNVML_SUCCESS\fP if \fIencoderCapacity\fP has been retrived
+\fBNVML_SUCCESS\fP if \fIencoderCapacity\fP has been retrieved
 .IP "\(bu" 2
 \fBNVML_ERROR_UNINITIALIZED\fP if the library has not been successfully initialized
 .IP "\(bu" 2
@@ -399,7 +399,7 @@ Retrieves information about all active e
 .PP
 An array of active encoder sessions is returned in the caller-supplied buffer pointed at by \fIsessionInfo\fP. The array elememt count is passed in \fIsessionCount\fP, and \fIsessionCount\fP is used to return the number of sessions written to the buffer.
 .PP
-If the supplied buffer is not large enough to accomodate the active session array, the function returns NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlEncoderSessionInfo_t array required in \fIsessionCount\fP. To query the number of active encoder sessions, call this function with *sessionCount = 0. The code will return NVML_SUCCESS with number of active encoder sessions updated in *sessionCount.
+If the supplied buffer is not large enough to accommodate the active session array, the function returns NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlEncoderSessionInfo_t array required in \fIsessionCount\fP. To query the number of active encoder sessions, call this function with *sessionCount = 0. The code will return NVML_SUCCESS with number of active encoder sessions updated in *sessionCount.
 .PP
 For Maxwell (TM) or newer fully supported devices.
 .PP
@@ -750,7 +750,7 @@ For Kepler (TM) or newer fully supported
 .br
 \fIdeviceID\fP Device ID and vendor ID of the device contained in single 32 bit value 
 .br
-\fIsubsystemID\fP Subsytem ID and subsytem vendor ID of the device contained in single 32 bit value
+\fIsubsystemID\fP Subsystem ID and subsystem vendor ID of the device contained in single 32 bit value
 .RE
 .PP
 \fBReturns:\fP
--- a/nvidia-cuda/extras/CUPTI/include/cupti_callbacks.h
+++ b/nvidia-cuda/extras/CUPTI/include/cupti_callbacks.h
@@ -487,7 +487,7 @@ CUptiResult CUPTIAPI cuptiSupportedDomai
  * \param subscriber Returns handle to initialize subscriber
  * \param callback The callback function
  * \param userdata A pointer to user data. This data will be passed to
- * the callback function via the \p userdata paramater.
+ * the callback function via the \p userdata parameter.
  *
  * \retval CUPTI_SUCCESS on success
  * \retval CUPTI_ERROR_NOT_INITIALIZED if unable to initialize CUPTI
--- a/nvidia-cuda/extras/CUPTI/sample/openacc_trace/openacc_trace.cpp
+++ b/nvidia-cuda/extras/CUPTI/sample/openacc_trace/openacc_trace.cpp
@@ -108,7 +108,7 @@ void finalize()
 }
 
 // acc_register_library is defined by the OpenACC tools interface
-// and allows to register this library with the OpenACC runtime.
+// and allows one to register this library with the OpenACC runtime.
 
 extern "C" void
 acc_register_library(void *profRegister, void *profUnregister, void *profLookup)
--- a/nvidia-cuda/include/cublasXt.h
+++ b/nvidia-cuda/include/cublasXt.h
@@ -73,7 +73,7 @@ cublasStatus_t CUBLASWINAPI cublasXtMaxB
 /* This routine selects the Gpus that the user want to use for CUBLAS-XT */
 cublasStatus_t CUBLASWINAPI cublasXtDeviceSelect(cublasXtHandle_t handle, int nbDevices, int deviceId[]);
 
-/* This routine allows to change the dimension of the tiles ( blockDim x blockDim ) */
+/* This routine allows one to change the dimension of the tiles ( blockDim x blockDim ) */
 cublasStatus_t CUBLASWINAPI cublasXtSetBlockDim(cublasXtHandle_t handle, int blockDim);
 cublasStatus_t CUBLASWINAPI cublasXtGetBlockDim(cublasXtHandle_t handle, int *blockDim);
 
--- a/nvidia-cuda/include/driver_types.h
+++ b/nvidia-cuda/include/driver_types.h
@@ -1232,7 +1232,7 @@ enum __device_builtin__ cudaLimit
  */
 enum __device_builtin__ cudaMemoryAdvise
 {
-    cudaMemAdviseSetReadMostly          = 1, /**< Data will mostly be read and only occassionally be written to */
+    cudaMemAdviseSetReadMostly          = 1, /**< Data will mostly be read and only occasionally be written to */
     cudaMemAdviseUnsetReadMostly        = 2, /**< Undo the effect of ::cudaMemAdviseSetReadMostly */
     cudaMemAdviseSetPreferredLocation   = 3, /**< Set the preferred location for the data as the specified device */
     cudaMemAdviseUnsetPreferredLocation = 4, /**< Clear the preferred location for the data */
@@ -1245,7 +1245,7 @@ enum __device_builtin__ cudaMemoryAdvise
  */
 enum __device_builtin__ cudaMemRangeAttribute
 {
-    cudaMemRangeAttributeReadMostly           = 1, /**< Whether the range will mostly be read and only occassionally be written to */
+    cudaMemRangeAttributeReadMostly           = 1, /**< Whether the range will mostly be read and only occasionally be written to */
     cudaMemRangeAttributePreferredLocation    = 2, /**< The preferred location of the range */
     cudaMemRangeAttributeAccessedBy           = 3, /**< Memory range has ::cudaMemAdviseSetAccessedBy set for specified device */
     cudaMemRangeAttributeLastPrefetchLocation = 4  /**< The last location to which the range was prefetched */
@@ -1606,8 +1606,8 @@ enum __device_builtin__ cudaCGScope {
 struct __device_builtin__ cudaLaunchParams
 {
     void *func;          /**< Device function symbol */
-    dim3 gridDim;        /**< Grid dimentions */
-    dim3 blockDim;       /**< Block dimentions */
+    dim3 gridDim;        /**< Grid dimensions */
+    dim3 blockDim;       /**< Block dimensions */
     void **args;         /**< Arguments */
     size_t sharedMem;    /**< Shared memory */
     cudaStream_t stream; /**< Stream identifier */
--- a/nvidia-cuda/include/nvml.h
+++ b/nvidia-cuda/include/nvml.h
@@ -664,7 +664,7 @@ typedef enum nvmlPStates_enum
 /**
  * GPU Operation Mode
  *
- * GOM allows to reduce power usage and optimize GPU throughput by disabling GPU features.
+ * GOM allows one to reduce power usage and optimize GPU throughput by disabling GPU features.
  *
  * Each GOM is designed to meet specific user needs.
  */
@@ -719,7 +719,7 @@ typedef enum nvmlReturn_enum
     NVML_ERROR_IN_USE = 19,             //!< An operation cannot be performed because the GPU is currently in use
     NVML_ERROR_MEMORY = 20,             //!< Insufficient memory
     NVML_ERROR_NO_DATA = 21,            //!<No data
-    NVML_ERROR_VGPU_ECC_NOT_SUPPORTED = 22,    //!< The requested vgpu operation is not available on target device, becasue ECC is enabled
+    NVML_ERROR_VGPU_ECC_NOT_SUPPORTED = 22,    //!< The requested vgpu operation is not available on target device, because ECC is enabled
     NVML_ERROR_UNKNOWN = 999            //!< An internal driver error occurred
 } nvmlReturn_t;
 
@@ -3600,7 +3600,7 @@ nvmlReturn_t DECLDIR nvmlDeviceGetEncode
  * array elememt count is passed in \a sessionCount, and \a sessionCount is used to return the number of sessions
  * written to the buffer.
  *
- * If the supplied buffer is not large enough to accomodate the active session array, the function returns
+ * If the supplied buffer is not large enough to accommodate the active session array, the function returns
  * NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlEncoderSessionInfo_t array required in \a sessionCount.
  * To query the number of active encoder sessions, call this function with *sessionCount = 0.  The code will return
  * NVML_SUCCESS with number of active encoder sessions updated in *sessionCount.
@@ -5082,7 +5082,7 @@ nvmlReturn_t DECLDIR nvmlDeviceSetVirtua
  * pointed at by \a vgpuTypeIds. The element count of nvmlVgpuTypeId_t array is passed in \a vgpuCount, and \a vgpuCount
  * is used to return the number of vGPU types written to the buffer.
  *
- * If the supplied buffer is not large enough to accomodate the vGPU type array, the function returns
+ * If the supplied buffer is not large enough to accommodate the vGPU type array, the function returns
  * NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlVgpuTypeId_t array required in \a vgpuCount.
  * To query the number of vGPU types supported for the GPU, call this function with *vgpuCount = 0.
  * The code will return NVML_ERROR_INSUFFICIENT_SIZE, or NVML_SUCCESS if no vGPU types are supported.
@@ -5112,7 +5112,7 @@ nvmlReturn_t DECLDIR nvmlDeviceGetSuppor
  * can concurrently run on a device.  For example, if only one vGPU type is allowed at a time on a device, then the creatable
  * list will be restricted to whatever vGPU type is already running on the device.
  *
- * If the supplied buffer is not large enough to accomodate the vGPU type array, the function returns
+ * If the supplied buffer is not large enough to accommodate the vGPU type array, the function returns
  * NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlVgpuTypeId_t array required in \a vgpuCount.
  * To query the number of vGPU types createable for the GPU, call this function with *vgpuCount = 0.
  * The code will return NVML_ERROR_INSUFFICIENT_SIZE, or NVML_SUCCESS if no vGPU types are creatable.
@@ -5177,7 +5177,7 @@ nvmlReturn_t DECLDIR nvmlVgpuTypeGetName
  *
  * @param vgpuTypeId               Handle to vGPU type
  * @param deviceID                 Device ID and vendor ID of the device contained in single 32 bit value
- * @param subsystemID              Subsytem ID and subsytem vendor ID of the device contained in single 32 bit value
+ * @param subsystemID              Subsystem ID and subsystem vendor ID of the device contained in single 32 bit value
  *
  * @return
  *         - \ref NVML_SUCCESS                 successful completion
@@ -5304,7 +5304,7 @@ nvmlReturn_t DECLDIR nvmlVgpuTypeGetMaxI
  * array elememt count is passed in \a vgpuCount, and \a vgpuCount is used to return the number of vGPU instances
  * written to the buffer.
  *
- * If the supplied buffer is not large enough to accomodate the vGPU instance array, the function returns
+ * If the supplied buffer is not large enough to accommodate the vGPU instance array, the function returns
  * NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlVgpuInstance_t array required in \a vgpuCount.
  * To query the number of active vGPU instances, call this function with *vgpuCount = 0.  The code will return
  * NVML_ERROR_INSUFFICIENT_SIZE, or NVML_SUCCESS if no vGPU Types are supported.
@@ -5480,7 +5480,7 @@ nvmlReturn_t DECLDIR nvmlVgpuInstanceGet
  * @param encoderCapacity          Reference to an unsigned int for the encoder capacity
  *
  * @return
- *         - \ref NVML_SUCCESS                 if \a encoderCapacity has been retrived
+ *         - \ref NVML_SUCCESS                 if \a encoderCapacity has been retrieved
  *         - \ref NVML_ERROR_UNINITIALIZED     if the library has not been successfully initialized
  *         - \ref NVML_ERROR_INVALID_ARGUMENT  if \a vgpuInstance is invalid, or \a encoderQueryType is invalid
  *         - \ref NVML_ERROR_UNKNOWN           on any unexpected error
@@ -5641,7 +5641,7 @@ nvmlReturn_t DECLDIR nvmlVgpuInstanceGet
  * array elememt count is passed in \a sessionCount, and \a sessionCount is used to return the number of sessions
  * written to the buffer.
  *
- * If the supplied buffer is not large enough to accomodate the active session array, the function returns
+ * If the supplied buffer is not large enough to accommodate the active session array, the function returns
  * NVML_ERROR_INSUFFICIENT_SIZE, with the element count of nvmlEncoderSessionInfo_t array required in \a sessionCount.
  * To query the number of active encoder sessions, call this function with *sessionCount = 0. The code will return
  * NVML_SUCCESS with number of active encoder sessions updated in *sessionCount.
@@ -5832,7 +5832,7 @@ nvmlReturn_t DECLDIR nvmlDeviceGetVgpuMe
  *
  * The caller passes in a buffer via \a compatibilityInfo, into which a compatibility information structure is written. The
  * structure defines the states in which the vGPU / VM may be booted on the physical GPU. If the vGPU / VM compatibility
- * with the physical GPU is limited, a limit code indicates the factor limiting compability.
+ * with the physical GPU is limited, a limit code indicates the factor limiting compatibility.
  * (see \ref nvmlVgpuPgpuCompatibilityLimitCode_t for details).
  *
  * Note: vGPU compatibility does not take into account dynamic capacity conditions that may limit a system's ability to
--- a/nvidia-cuda/libnsight/plugins/org.eclipse.ui.intro.universal_3.2.700.v20130904-1701/themes/purpleMesh/html/root.css
+++ b/nvidia-cuda/libnsight/plugins/org.eclipse.ui.intro.universal_3.2.700.v20130904-1701/themes/purpleMesh/html/root.css
@@ -60,7 +60,7 @@ body {
 }
 /* specify a width for Moz so we can center.  
  * **Important** If additional links are added, we will have to increase this width 
- * to accomodate them, otherwise they will wrap to a new line 
+ * to accommodate them, otherwise they will wrap to a new line 
  */
 
 #links-background > #page-links {
--- a/nvidia-cuda/libnvvp/plugins/org.eclipse.ui.intro.universal_3.2.700.v20130904-1701/themes/purpleMesh/html/root.css
+++ b/nvidia-cuda/libnvvp/plugins/org.eclipse.ui.intro.universal_3.2.700.v20130904-1701/themes/purpleMesh/html/root.css
@@ -60,7 +60,7 @@ body {
 }
 /* specify a width for Moz so we can center.  
  * **Important** If additional links are added, we will have to increase this width 
- * to accomodate them, otherwise they will wrap to a new line 
+ * to accommodate them, otherwise they will wrap to a new line 
  */
 
 #links-background > #page-links {
--- a/nvidia-cuda/doc/man/man3/nvml.3
+++ b/nvidia-cuda/doc/man/man3/nvml.3
@@ -123,7 +123,7 @@ The caller passes in a buffer via \fIpgp
 .PP
 Takes a vGPU instance metadata structure read from \fBnvmlVgpuInstanceGetMetadata()\fP, and a vGPU metadata structure for a physical GPU read from \fBnvmlDeviceGetVgpuMetadata()\fP, and returns compatibility information of the vGPU instance and the physical GPU.
 .PP
-The caller passes in a buffer via \fIcompatibilityInfo\fP, into which a compatibility information structure is written. The structure defines the states in which the vGPU / VM may be booted on the physical GPU. If the vGPU / VM compatibility with the physical GPU is limited, a limit code indicates the factor limiting compability. (see \fBnvmlVgpuPgpuCompatibilityLimitCode_t\fP for details).
+The caller passes in a buffer via \fIcompatibilityInfo\fP, into which a compatibility information structure is written. The structure defines the states in which the vGPU / VM may be booted on the physical GPU. If the vGPU / VM compatibility with the physical GPU is limited, a limit code indicates the factor limiting compatibility. (see \fBnvmlVgpuPgpuCompatibilityLimitCode_t\fP for details).
 .PP
 Note: vGPU compatibility does not take into account dynamic capacity conditions that may limit a system's ability to boot a given vGPU or associated VM.
 .PP
